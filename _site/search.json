[
  {
    "objectID": "00_R_basics/R_basics.html",
    "href": "00_R_basics/R_basics.html",
    "title": "Getting Started with R",
    "section": "",
    "text": "Introduction\n\nThis guide shows how to:\n\nDownload and install R and RStudio\nUnderstand how base R differs from RStudio\nNavigate the RStudio environment (the 4 panes)\nFormat flat files (like CSV) for loading\nLoad a dataset (flat file and pointers to other resources)\nInstall and load libraries\nCreate objects\nConduct basic analyses\nSave datasets\nSave R Markdown and Quarto files\n\n\n\n1 Download and Install R and RStudio\n\nR is the programming language. RStudio (by Posit) is a popular Integrated Development Environment (IDE) for R.\nInstall R first, then RStudio.\n\nSteps\n\nDownload R (CRAN):\n\n\nhttps://cran.r-project.org/\nClick “Download R for Windows” or “macOS” or “Linux”\nChoose the latest release, then run the installer\n\n\nDownload RStudio Desktop (free):\n\n\nhttps://posit.co/download/rstudio-desktop/\nDownload the installer for your OS and run it\nOpen RStudio after installing (R should already be installed)\n\nCheck versions\n\nR.version.string\n\n[1] \"R version 4.4.3 (2025-02-28)\"\n\n# If running inside RStudio, this may show RStudio version:\nif (exists(\"RStudio.Version\")) {\n  try({\n    v &lt;- RStudio.Version()\n    paste(\"RStudio version:\", v$version)\n  }, silent = TRUE)\n}\n\n\n\n2 How Base R Differs from RStudio\n\nBase R\n\nThe language + interpreter/engine\nComes with a console and basic GUI (varies by OS)\nYou can run scripts and commands via the R console or terminal\n\nRStudio IDE (by Posit)\n\nA graphical environment wrapping R\nOffers script editor, plotting viewer, environment browser, package manager, project management, and integrated help\nMakes development, reproducibility, and visualization easier, but does not replace R itself\n\n\nExample: Base R functionality (works the same in RStudio since RStudio calls R under the hood)\n\n# Base R calculations\nx &lt;- c(1, 2, 3, 4, 5)\nmean(x)\n\n[1] 3\n\nsd(x)\n\n[1] 1.581139\n\nsum(x^2)\n\n[1] 55\n\n\n\n\n3 Introduction to the RStudio Environment (The 4 Panes)\n\nSource (top-left, by default)\n\nYour editor for .R scripts, .Rmd, .qmd files\nRun code lines or chunks into the Console\n\nConsole (bottom-left)\n\nWhere R commands execute\nShows outputs, errors, warnings\n\nEnvironment/History (top-right)\n\nEnvironment: objects currently in memory\nHistory: previously run commands\n\nFiles/Plots/Packages/Help/Viewer (bottom-right)\n\nFiles: browse project files\nPlots: view figures\nPackages: installed packages and load/unload controls\nHelp: documentation for functions and packages\nViewer: renders HTML content (e.g., Quarto docs)\n\n\n\n\n\nRStudio window\n\n\nQuick demonstrations\n\n# Create a few objects (watch the Environment pane update)\nnums &lt;- rnorm(10)\ndf &lt;- data.frame(id = 1:5, value = c(10, 20, 15, 30, NA))\n\n# Use Help pane: open documentation\nhelp(\"mean\")   # or ?mean\n\n# Show a basic plot (appears in Plots tab)\nplot(nums, type = \"b\", main = \"Demo plot\", xlab = \"Index\", ylab = \"Value\")\n\n\n\n\n\n\n\n\n\n\n4 Formatting Flat Files for Loading\nGood practices for CSV/TSV flat files\n\nUse a header row with short, clear, alphanumeric column names (avoid spaces; use underscores if needed)\nUse UTF-8 encoding\nUse a consistent delimiter (comma for CSV, tab for TSV)\nRepresent missing values consistently (e.g., empty cell or NA; avoid mixed values like “-”, “N/A”, “null”)\nUse ISO 8601 for dates (YYYY-MM-DD) and include time zones if timestamps are present\nAvoid embedded line breaks in cells; if present, ensure proper quoting\nKeep one “tidy” table per file: each row is one observation, each column is one variable\n\nCreate and save a well-formatted CSV\n\n# Example tidy dataset\ntidy_example &lt;- data.frame(\n  subject_id = 1:6,\n  group = c(\"control\", \"control\", \"control\", \"treatment\", \"treatment\", \"treatment\"),\n  age_years = c(34, 45, 51, 29, 40, NA),\n  visit_date = as.Date(c(\"2025-01-10\", \"2025-01-12\", \"2025-01-13\", \"2025-01-11\", \"2025-01-12\", \"2025-01-14\")),\n  score = c(87, 90, 85, 92, 88, 91)\n)\n\n# Create a data folder, then save CSV\ndir.create(\"data\", showWarnings = FALSE)\ncsv_path &lt;- file.path(\"data\", \"tidy_example.csv\")\nwrite.csv(tidy_example, csv_path, row.names = FALSE, na = \"\")\ncsv_path\n\n[1] \"data/tidy_example.csv\"\n\n\n\n\n5 Loading a Dataset (Flat File and Other Resources)\nLoad the CSV using base R\n\nloaded_base &lt;- read.csv(csv_path, stringsAsFactors = FALSE)\nstr(loaded_base)\n\n'data.frame':   6 obs. of  5 variables:\n $ subject_id: int  1 2 3 4 5 6\n $ group     : chr  \"control\" \"control\" \"control\" \"treatment\" ...\n $ age_years : int  34 45 51 29 40 NA\n $ visit_date: chr  \"2025-01-10\" \"2025-01-12\" \"2025-01-13\" \"2025-01-11\" ...\n $ score     : int  87 90 85 92 88 91\n\nhead(loaded_base)\n\n\n  \n\n\n\nLoad the CSV using readr (tidyverse) for better performance and type control\n\n# Install readr if needed (run once; eval is FALSE so it won't execute automatically)\n# install.packages(\"readr\")\n\n\n# If readr is available, demonstrate its use safely\nif (requireNamespace(\"readr\", quietly = TRUE)) {\n  loaded_readr &lt;- readr::read_csv(csv_path, show_col_types = FALSE)\n  print(loaded_readr)\n}\n\n# A tibble: 6 × 5\n  subject_id group     age_years visit_date score\n       &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;date&gt;     &lt;dbl&gt;\n1          1 control          34 2025-01-10    87\n2          2 control          45 2025-01-12    90\n3          3 control          51 2025-01-13    85\n4          4 treatment        29 2025-01-11    92\n5          5 treatment        40 2025-01-12    88\n6          6 treatment        NA 2025-01-14    91\n\n\nHandling column types and missing values explicitly with readr\n\nif (requireNamespace(\"readr\", quietly = TRUE)) {\n  loaded_typed &lt;- readr::read_csv(\n    csv_path,\n    col_types = readr::cols(\n      subject_id = readr::col_integer(),\n      group = readr::col_factor(levels = c(\"control\", \"treatment\")),\n      age_years = readr::col_double(),\n      visit_date = readr::col_date(),\n      score = readr::col_double()\n    ),\n    show_col_types = FALSE\n  )\n  str(loaded_typed)\n}\n\nspc_tbl_ [6 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ subject_id: int [1:6] 1 2 3 4 5 6\n $ group     : Factor w/ 2 levels \"control\",\"treatment\": 1 1 1 2 2 2\n $ age_years : num [1:6] 34 45 51 29 40 NA\n $ visit_date: Date[1:6], format: \"2025-01-10\" \"2025-01-12\" ...\n $ score     : num [1:6] 87 90 85 92 88 91\n - attr(*, \"spec\")=\n  .. cols(\n  ..   subject_id = col_integer(),\n  ..   group = col_factor(levels = c(\"control\", \"treatment\"), ordered = FALSE, include_na = FALSE),\n  ..   age_years = col_double(),\n  ..   visit_date = col_date(format = \"\"),\n  ..   score = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nReading Excel files\n\n# install.packages(\"readxl\")  # run once\nif (requireNamespace(\"readxl\", quietly = TRUE)) {\n  # Example: readxl::read_excel(\"data/example.xlsx\", sheet = 1)\n  # (We won’t read here unless a file exists)\n}\n\nNULL\n\n\nOther dataset resources\n\nBuilt-in datasets: datasets::mtcars, iris, airquality\nPublic datasets:\n\npalmerpenguins: https://allisonhorst.github.io/palmerpenguins/\nTidyTuesday datasets: https://github.com/rfordatascience/tidytuesday\nUCI Machine Learning Repository: https://archive.ics.uci.edu/\nKaggle: https://www.kaggle.com/datasets\ndata.gov (US): https://data.gov/\nWorld Bank Data: https://data.worldbank.org/\n\n\n\n\n6 Installing and Loading Libraries\nInstall packages (run once; do not run inside production pipelines without a lockfile)\n\n# Example install (set eval: false to avoid automatic install)\n# install.packages(c(\"tidyverse\", \"readr\", \"dplyr\", \"ggplot2\", \"readxl\", \"data.table\"))\n\nLoad packages\n\n# Load if available; fall back gracefully if not\nloaded_pkgs &lt;- c()\nfor (pkg in c(\"dplyr\", \"ggplot2\")) {\n  if (requireNamespace(pkg, quietly = TRUE)) {\n    library(pkg, character.only = TRUE)\n    loaded_pkgs &lt;- c(loaded_pkgs, pkg)\n  }\n}\nloaded_pkgs\n\n[1] \"dplyr\"   \"ggplot2\"\n\n\nNotes\n\nUse install.packages(“packagename”) once per machine or project\nUse library(packagename) in each session/script where needed\nConsider project environments for reproducibility (e.g., renv)\n\n\n\n7 Creating Objects\nBasic objects\n\n# Numeric and character vectors\na &lt;- c(10, 20, 30)\nb &lt;- c(\"alpha\", \"beta\", \"gamma\")\n\n# Factors\ngrp &lt;- factor(c(\"control\", \"treatment\", \"control\"), levels = c(\"control\", \"treatment\"))\n\n# Matrices\nm &lt;- matrix(1:9, nrow = 3)\n\n# Lists (heterogeneous containers)\nmy_list &lt;- list(nums = a, labels = b, flag = TRUE)\n\n# Data frames (tabular)\ndf2 &lt;- data.frame(id = 1:3, group = grp, score = c(88, 92, 85))\nstr(df2)\n\n'data.frame':   3 obs. of  3 variables:\n $ id   : int  1 2 3\n $ group: Factor w/ 2 levels \"control\",\"treatment\": 1 2 1\n $ score: num  88 92 85\n\n# Functions\nadd_two &lt;- function(x) x + 2\nadd_two(5)\n\n[1] 7\n\n\n\n\n8 Conducting Analyses\nDescriptive statistics (base R)\n\nx &lt;- rnorm(100, mean = 50, sd = 10)\nsummary(x)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  27.40   43.00   50.43   50.40   56.94   83.83 \n\nmean(x); median(x); sd(x); quantile(x, probs = c(0.25, 0.5, 0.75))\n\n[1] 50.39509\n\n\n[1] 50.42874\n\n\n[1] 9.84919\n\n\n     25%      50%      75% \n42.99694 50.42874 56.94257 \n\n\nGroup-wise summaries (dplyr, if available)\n\nif (requireNamespace(\"dplyr\", quietly = TRUE)) {\n  library(dplyr)\n  loaded_base %&gt;%\n    group_by(group) %&gt;%\n    summarise(\n      n = n(),\n      mean_score = mean(score, na.rm = TRUE),\n      mean_age = mean(age_years, na.rm = TRUE)\n    )\n}\n\n\n  \n\n\n\nVisualization (ggplot2, if available)\n\nif (requireNamespace(\"ggplot2\", quietly = TRUE)) {\n  library(ggplot2)\n  ggplot(loaded_base, aes(x = group, y = score, fill = group)) +\n    geom_boxplot() +\n    geom_jitter(width = 0.1, alpha = 0.6) +\n    labs(title = \"Scores by Group\", x = \"Group\", y = \"Score\") +\n    theme_minimal()\n}\n\n\n\n\n\n\n\n\nLinear regression\n\n# Fit a simple model on built-in mtcars dataset\nfit &lt;- lm(mpg ~ wt + cyl, data = mtcars)\nsummary(fit)\n\n\nCall:\nlm(formula = mpg ~ wt + cyl, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.2893 -1.5512 -0.4684  1.5743  6.1004 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  39.6863     1.7150  23.141  &lt; 2e-16 ***\nwt           -3.1910     0.7569  -4.216 0.000222 ***\ncyl          -1.5078     0.4147  -3.636 0.001064 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.568 on 29 degrees of freedom\nMultiple R-squared:  0.8302,    Adjusted R-squared:  0.8185 \nF-statistic: 70.91 on 2 and 29 DF,  p-value: 6.809e-12\n\n\nT-test (group comparison)\n\n# Compare mpg for automatic vs manual transmissions\nt.test(mpg ~ am, data = mtcars)\n\n\n    Welch Two Sample t-test\n\ndata:  mpg by am\nt = -3.7671, df = 18.332, p-value = 0.001374\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -11.280194  -3.209684\nsample estimates:\nmean in group 0 mean in group 1 \n       17.14737        24.39231 \n\n\nContingency table and chi-squared test\n\ntbl &lt;- table(mtcars$cyl, mtcars$gear)\ntbl\n\n   \n     3  4  5\n  4  1  8  2\n  6  2  4  1\n  8 12  0  2\n\nchisq.test(tbl)\n\n\n    Pearson's Chi-squared test\n\ndata:  tbl\nX-squared = 18.036, df = 4, p-value = 0.001214\n\n\n\n\n9 Saving Datasets\nSave to CSV (portable)\n\n# Save mtcars as CSV\nout_csv &lt;- file.path(\"data\", \"mtcars_export.csv\")\ndir.create(\"data\", showWarnings = FALSE)\nwrite.csv(mtcars, out_csv, row.names = FALSE)\nout_csv\n\n[1] \"data/mtcars_export.csv\"\n\n\nSave to RDS (preserves R types precisely, single object)\n\nout_rds &lt;- file.path(\"data\", \"mtcars.rds\")\nsaveRDS(mtcars, out_rds)\n# Load back\nmtcars_loaded &lt;- readRDS(out_rds)\nidentical(mtcars, mtcars_loaded)\n\n[1] TRUE\n\n\nSave multiple objects to .RData (workspace-like)\n\nout_rdata &lt;- file.path(\"data\", \"analysis_objects.RData\")\nobj1 &lt;- 123\nobj2 &lt;- data.frame(x = 1:3, y = c(\"a\", \"b\", \"c\"))\nsave(obj1, obj2, file = out_rdata)\n# Load back\nrm(obj1, obj2)\nload(out_rdata)\nobj1; obj2\n\n[1] 123\n\n\n\n  \n\n\n\n\n\n10 Saving R Markdown and Quarto Files\nSaving files\n\nIn RStudio:\n\nFile -&gt; New File -&gt; Quarto Document\nFile -&gt; Save (choose .qmd extension)\nFor R Markdown: File -&gt; New File -&gt; R Markdown, then Save as .Rmd\n\n\nRendering (turn .qmd or .Rmd into HTML/PDF/Word)\n\n# Quarto render (requires Quarto installed)\n# install.packages(\"quarto\") is not needed; Quarto is a separate tool you install from https://quarto.org/\n# From R you can call:\nif (requireNamespace(\"quarto\", quietly = TRUE)) {\n  # quarto::quarto_render(\"your_document.qmd\")\n}\n\nNULL\n\n\n\n# R Markdown render (requires rmarkdown package)\n# install.packages(\"rmarkdown\")  # run once\nif (requireNamespace(\"rmarkdown\", quietly = TRUE)) {\n  # rmarkdown::render(\"your_document.Rmd\", output_format = \"html_document\")\n}\n\nNULL\n\n\nCommand-line rendering (outside R)\n\nQuarto:\n\nInstall Quarto: https://quarto.org/docs/get-started/\nIn a terminal: quarto render your_document.qmd\n\nR Markdown (legacy):\n\nIn RStudio: click “Knit”\nOr in R: rmarkdown::render(“your_document.Rmd”)\n\n\nExport formats\n\nHTML (default), PDF (requires LaTeX), Word (docx)\nChoose output format in the YAML header or via render arguments\n\n\n\n11 Sources and Further Reading\n\nR (CRAN) downloads: https://cran.r-project.org/\nRStudio Desktop by Posit: https://posit.co/download/rstudio-desktop/\nQuarto documentation: https://quarto.org/docs/\nR for Data Science (2e): https://r4ds.hadley.nz/\nAdvanced R (3e): https://adv-r.hadley.nz/\nTidyverse packages: https://www.tidyverse.org/\nreadr (fast reading/writing): https://readr.tidyverse.org/\ndplyr (data manipulation): https://dplyr.tidyverse.org/\nggplot2 (visualization): https://ggplot2.tidyverse.org/\nR Markdown (legacy): https://rmarkdown.rstudio.com/\nBase R documentation (manuals): https://cran.r-project.org/manuals.html\nRStudio IDE docs: https://docs.posit.co/ide/\nData import best practices (readr vignette): https://readr.tidyverse.org/articles/readr.html\nPalmer Penguins dataset: https://allisonhorst.github.io/palmerpenguins/\nTidyTuesday: https://github.com/rfordatascience/tidytuesday\nUCI ML Repository: https://archive.ics.uci.edu/\nKaggle datasets: https://www.kaggle.com/datasets\ndata.gov: https://data.gov/"
  },
  {
    "objectID": "R_basics.html",
    "href": "R_basics.html",
    "title": "Getting Started with R",
    "section": "",
    "text": "Introduction\n\nThis guide shows how to:\n\nDownload and install R and RStudio\nUnderstand how base R differs from RStudio\nNavigate the RStudio environment (the 4 panes)\nFormat flat files (like CSV) for loading\nLoad a dataset (flat file and pointers to other resources)\nInstall and load libraries\nCreate objects\nConduct basic analyses\nSave datasets\nSave R Markdown and Quarto files\n\n\n\n1 Download and Install R and RStudio\n\nR is the programming language. RStudio (by Posit) is a popular Integrated Development Environment (IDE) for R.\nInstall R first, then RStudio.\n\nSteps\n\nDownload R (CRAN):\n\n\nhttps://cran.r-project.org/\nClick “Download R for Windows” or “macOS” or “Linux”\nChoose the latest release, then run the installer\n\n\nDownload RStudio Desktop (free):\n\n\nhttps://posit.co/download/rstudio-desktop/\nDownload the installer for your OS and run it\nOpen RStudio after installing (R should already be installed)\n\nCheck versions\n\nR.version.string\n\n[1] \"R version 4.4.3 (2025-02-28)\"\n\n# If running inside RStudio, this may show RStudio version:\nif (exists(\"RStudio.Version\")) {\n  try({\n    v &lt;- RStudio.Version()\n    paste(\"RStudio version:\", v$version)\n  }, silent = TRUE)\n}\n\n\n\n2 How Base R Differs from RStudio\n\nBase R\n\nThe language + interpreter/engine\nComes with a console and basic GUI (varies by OS)\nYou can run scripts and commands via the R console or terminal\n\nRStudio IDE (by Posit)\n\nA graphical environment wrapping R\nOffers script editor, plotting viewer, environment browser, package manager, project management, and integrated help\nMakes development, reproducibility, and visualization easier, but does not replace R itself\n\n\nExample: Base R functionality (works the same in RStudio since RStudio calls R under the hood)\n\n# Base R calculations\nx &lt;- c(1, 2, 3, 4, 5)\nmean(x)\n\n[1] 3\n\nsd(x)\n\n[1] 1.581139\n\nsum(x^2)\n\n[1] 55\n\n\n\n\n3 Introduction to the RStudio Environment (The 4 Panes)\n\nSource (top-left, by default)\n\nYour editor for .R scripts, .Rmd, .qmd files\nRun code lines or chunks into the Console\n\nConsole (bottom-left)\n\nWhere R commands execute\nShows outputs, errors, warnings\n\nEnvironment/History (top-right)\n\nEnvironment: objects currently in memory\nHistory: previously run commands\n\nFiles/Plots/Packages/Help/Viewer (bottom-right)\n\nFiles: browse project files\nPlots: view figures\nPackages: installed packages and load/unload controls\nHelp: documentation for functions and packages\nViewer: renders HTML content (e.g., Quarto docs)\n\n\n\n\n\nRStudio window\n\n\nQuick demonstrations\n\n# Create a few objects (watch the Environment pane update)\nnums &lt;- rnorm(10)\ndf &lt;- data.frame(id = 1:5, value = c(10, 20, 15, 30, NA))\n\n# Use Help pane: open documentation\nhelp(\"mean\")   # or ?mean\n\n# Show a basic plot (appears in Plots tab)\nplot(nums, type = \"b\", main = \"Demo plot\", xlab = \"Index\", ylab = \"Value\")\n\n\n\n\n\n\n\n\n\n\n4 Formatting Flat Files for Loading\nGood practices for CSV/TSV flat files\n\nUse a header row with short, clear, alphanumeric column names (avoid spaces; use underscores if needed)\nUse UTF-8 encoding\nUse a consistent delimiter (comma for CSV, tab for TSV)\nRepresent missing values consistently (e.g., empty cell or NA; avoid mixed values like “-”, “N/A”, “null”)\nUse ISO 8601 for dates (YYYY-MM-DD) and include time zones if timestamps are present\nAvoid embedded line breaks in cells; if present, ensure proper quoting\nKeep one “tidy” table per file: each row is one observation, each column is one variable\n\nCreate and save a well-formatted CSV\n\n# Example tidy dataset\ntidy_example &lt;- data.frame(\n  subject_id = 1:6,\n  group = c(\"control\", \"control\", \"control\", \"treatment\", \"treatment\", \"treatment\"),\n  age_years = c(34, 45, 51, 29, 40, NA),\n  visit_date = as.Date(c(\"2025-01-10\", \"2025-01-12\", \"2025-01-13\", \"2025-01-11\", \"2025-01-12\", \"2025-01-14\")),\n  score = c(87, 90, 85, 92, 88, 91)\n)\n\n# Create a data folder, then save CSV\ndir.create(\"data\", showWarnings = FALSE)\ncsv_path &lt;- file.path(\"data\", \"tidy_example.csv\")\nwrite.csv(tidy_example, csv_path, row.names = FALSE, na = \"\")\ncsv_path\n\n[1] \"data/tidy_example.csv\"\n\n\n\n\n5 Loading a Dataset (Flat File and Other Resources)\nLoad the CSV using base R\n\nloaded_base &lt;- read.csv(csv_path, stringsAsFactors = FALSE)\nstr(loaded_base)\n\n'data.frame':   6 obs. of  5 variables:\n $ subject_id: int  1 2 3 4 5 6\n $ group     : chr  \"control\" \"control\" \"control\" \"treatment\" ...\n $ age_years : int  34 45 51 29 40 NA\n $ visit_date: chr  \"2025-01-10\" \"2025-01-12\" \"2025-01-13\" \"2025-01-11\" ...\n $ score     : int  87 90 85 92 88 91\n\nhead(loaded_base)\n\n\n  \n\n\n\nLoad the CSV using readr (tidyverse) for better performance and type control\n\n# Install readr if needed (run once; eval is FALSE so it won't execute automatically)\n# install.packages(\"readr\")\n\n\n# If readr is available, demonstrate its use safely\nif (requireNamespace(\"readr\", quietly = TRUE)) {\n  loaded_readr &lt;- readr::read_csv(csv_path, show_col_types = FALSE)\n  print(loaded_readr)\n}\n\n# A tibble: 6 × 5\n  subject_id group     age_years visit_date score\n       &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;date&gt;     &lt;dbl&gt;\n1          1 control          34 2025-01-10    87\n2          2 control          45 2025-01-12    90\n3          3 control          51 2025-01-13    85\n4          4 treatment        29 2025-01-11    92\n5          5 treatment        40 2025-01-12    88\n6          6 treatment        NA 2025-01-14    91\n\n\nHandling column types and missing values explicitly with readr\n\nif (requireNamespace(\"readr\", quietly = TRUE)) {\n  loaded_typed &lt;- readr::read_csv(\n    csv_path,\n    col_types = readr::cols(\n      subject_id = readr::col_integer(),\n      group = readr::col_factor(levels = c(\"control\", \"treatment\")),\n      age_years = readr::col_double(),\n      visit_date = readr::col_date(),\n      score = readr::col_double()\n    ),\n    show_col_types = FALSE\n  )\n  str(loaded_typed)\n}\n\nspc_tbl_ [6 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ subject_id: int [1:6] 1 2 3 4 5 6\n $ group     : Factor w/ 2 levels \"control\",\"treatment\": 1 1 1 2 2 2\n $ age_years : num [1:6] 34 45 51 29 40 NA\n $ visit_date: Date[1:6], format: \"2025-01-10\" \"2025-01-12\" ...\n $ score     : num [1:6] 87 90 85 92 88 91\n - attr(*, \"spec\")=\n  .. cols(\n  ..   subject_id = col_integer(),\n  ..   group = col_factor(levels = c(\"control\", \"treatment\"), ordered = FALSE, include_na = FALSE),\n  ..   age_years = col_double(),\n  ..   visit_date = col_date(format = \"\"),\n  ..   score = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nReading Excel files\n\n# install.packages(\"readxl\")  # run once\nif (requireNamespace(\"readxl\", quietly = TRUE)) {\n  # Example: readxl::read_excel(\"data/example.xlsx\", sheet = 1)\n  # (We won’t read here unless a file exists)\n}\n\nNULL\n\n\nOther dataset resources\n\nBuilt-in datasets: datasets::mtcars, iris, airquality\nPublic datasets:\n\npalmerpenguins: https://allisonhorst.github.io/palmerpenguins/\nTidyTuesday datasets: https://github.com/rfordatascience/tidytuesday\nUCI Machine Learning Repository: https://archive.ics.uci.edu/\nKaggle: https://www.kaggle.com/datasets\ndata.gov (US): https://data.gov/\nWorld Bank Data: https://data.worldbank.org/\n\n\n\n\n6 Installing and Loading Libraries\nInstall packages (run once; do not run inside production pipelines without a lockfile)\n\n# Example install (set eval: false to avoid automatic install)\n# install.packages(c(\"tidyverse\", \"readr\", \"dplyr\", \"ggplot2\", \"readxl\", \"data.table\"))\n\nLoad packages\n\n# Load if available; fall back gracefully if not\nloaded_pkgs &lt;- c()\nfor (pkg in c(\"dplyr\", \"ggplot2\")) {\n  if (requireNamespace(pkg, quietly = TRUE)) {\n    library(pkg, character.only = TRUE)\n    loaded_pkgs &lt;- c(loaded_pkgs, pkg)\n  }\n}\nloaded_pkgs\n\n[1] \"dplyr\"   \"ggplot2\"\n\n\nNotes\n\nUse install.packages(“packagename”) once per machine or project\nUse library(packagename) in each session/script where needed\nConsider project environments for reproducibility (e.g., renv)\n\n\n\n7 Creating Objects\nBasic objects\n\n# Numeric and character vectors\na &lt;- c(10, 20, 30)\nb &lt;- c(\"alpha\", \"beta\", \"gamma\")\n\n# Factors\ngrp &lt;- factor(c(\"control\", \"treatment\", \"control\"), levels = c(\"control\", \"treatment\"))\n\n# Matrices\nm &lt;- matrix(1:9, nrow = 3)\n\n# Lists (heterogeneous containers)\nmy_list &lt;- list(nums = a, labels = b, flag = TRUE)\n\n# Data frames (tabular)\ndf2 &lt;- data.frame(id = 1:3, group = grp, score = c(88, 92, 85))\nstr(df2)\n\n'data.frame':   3 obs. of  3 variables:\n $ id   : int  1 2 3\n $ group: Factor w/ 2 levels \"control\",\"treatment\": 1 2 1\n $ score: num  88 92 85\n\n# Functions\nadd_two &lt;- function(x) x + 2\nadd_two(5)\n\n[1] 7\n\n\n\n\n8 Conducting Analyses\nDescriptive statistics (base R)\n\nx &lt;- rnorm(100, mean = 50, sd = 10)\nsummary(x)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.03   45.71   50.65   51.09   57.17   79.13 \n\nmean(x); median(x); sd(x); quantile(x, probs = c(0.25, 0.5, 0.75))\n\n[1] 51.08511\n\n\n[1] 50.6492\n\n\n[1] 8.869608\n\n\n     25%      50%      75% \n45.70902 50.64920 57.16538 \n\n\nGroup-wise summaries (dplyr, if available)\n\nif (requireNamespace(\"dplyr\", quietly = TRUE)) {\n  library(dplyr)\n  loaded_base %&gt;%\n    group_by(group) %&gt;%\n    summarise(\n      n = n(),\n      mean_score = mean(score, na.rm = TRUE),\n      mean_age = mean(age_years, na.rm = TRUE)\n    )\n}\n\n\n  \n\n\n\nVisualization (ggplot2, if available)\n\nif (requireNamespace(\"ggplot2\", quietly = TRUE)) {\n  library(ggplot2)\n  ggplot(loaded_base, aes(x = group, y = score, fill = group)) +\n    geom_boxplot() +\n    geom_jitter(width = 0.1, alpha = 0.6) +\n    labs(title = \"Scores by Group\", x = \"Group\", y = \"Score\") +\n    theme_minimal()\n}\n\n\n\n\n\n\n\n\nLinear regression\n\n# Fit a simple model on built-in mtcars dataset\nfit &lt;- lm(mpg ~ wt + cyl, data = mtcars)\nsummary(fit)\n\n\nCall:\nlm(formula = mpg ~ wt + cyl, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.2893 -1.5512 -0.4684  1.5743  6.1004 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  39.6863     1.7150  23.141  &lt; 2e-16 ***\nwt           -3.1910     0.7569  -4.216 0.000222 ***\ncyl          -1.5078     0.4147  -3.636 0.001064 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.568 on 29 degrees of freedom\nMultiple R-squared:  0.8302,    Adjusted R-squared:  0.8185 \nF-statistic: 70.91 on 2 and 29 DF,  p-value: 6.809e-12\n\n\nT-test (group comparison)\n\n# Compare mpg for automatic vs manual transmissions\nt.test(mpg ~ am, data = mtcars)\n\n\n    Welch Two Sample t-test\n\ndata:  mpg by am\nt = -3.7671, df = 18.332, p-value = 0.001374\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -11.280194  -3.209684\nsample estimates:\nmean in group 0 mean in group 1 \n       17.14737        24.39231 \n\n\nContingency table and chi-squared test\n\ntbl &lt;- table(mtcars$cyl, mtcars$gear)\ntbl\n\n   \n     3  4  5\n  4  1  8  2\n  6  2  4  1\n  8 12  0  2\n\nchisq.test(tbl)\n\n\n    Pearson's Chi-squared test\n\ndata:  tbl\nX-squared = 18.036, df = 4, p-value = 0.001214\n\n\n\n\n9 Saving Datasets\nSave to CSV (portable)\n\n# Save mtcars as CSV\nout_csv &lt;- file.path(\"data\", \"mtcars_export.csv\")\ndir.create(\"data\", showWarnings = FALSE)\nwrite.csv(mtcars, out_csv, row.names = FALSE)\nout_csv\n\n[1] \"data/mtcars_export.csv\"\n\n\nSave to RDS (preserves R types precisely, single object)\n\nout_rds &lt;- file.path(\"data\", \"mtcars.rds\")\nsaveRDS(mtcars, out_rds)\n# Load back\nmtcars_loaded &lt;- readRDS(out_rds)\nidentical(mtcars, mtcars_loaded)\n\n[1] TRUE\n\n\nSave multiple objects to .RData (workspace-like)\n\nout_rdata &lt;- file.path(\"data\", \"analysis_objects.RData\")\nobj1 &lt;- 123\nobj2 &lt;- data.frame(x = 1:3, y = c(\"a\", \"b\", \"c\"))\nsave(obj1, obj2, file = out_rdata)\n# Load back\nrm(obj1, obj2)\nload(out_rdata)\nobj1; obj2\n\n[1] 123\n\n\n\n  \n\n\n\n\n\n10 Saving R Markdown and Quarto Files\nSaving files\n\nIn RStudio:\n\nFile -&gt; New File -&gt; Quarto Document\nFile -&gt; Save (choose .qmd extension)\nFor R Markdown: File -&gt; New File -&gt; R Markdown, then Save as .Rmd\n\n\nRendering (turn .qmd or .Rmd into HTML/PDF/Word)\n\n# Quarto render (requires Quarto installed)\n# install.packages(\"quarto\") is not needed; Quarto is a separate tool you install from https://quarto.org/\n# From R you can call:\nif (requireNamespace(\"quarto\", quietly = TRUE)) {\n  # quarto::quarto_render(\"your_document.qmd\")\n}\n\nNULL\n\n\n\n# R Markdown render (requires rmarkdown package)\n# install.packages(\"rmarkdown\")  # run once\nif (requireNamespace(\"rmarkdown\", quietly = TRUE)) {\n  # rmarkdown::render(\"your_document.Rmd\", output_format = \"html_document\")\n}\n\nNULL\n\n\nCommand-line rendering (outside R)\n\nQuarto:\n\nInstall Quarto: https://quarto.org/docs/get-started/\nIn a terminal: quarto render your_document.qmd\n\nR Markdown (legacy):\n\nIn RStudio: click “Knit”\nOr in R: rmarkdown::render(“your_document.Rmd”)\n\n\nExport formats\n\nHTML (default), PDF (requires LaTeX), Word (docx)\nChoose output format in the YAML header or via render arguments\n\n\n\n11 Sources and Further Reading\n\nR (CRAN) downloads: https://cran.r-project.org/\nRStudio Desktop by Posit: https://posit.co/download/rstudio-desktop/\nQuarto documentation: https://quarto.org/docs/\nR for Data Science (2e): https://r4ds.hadley.nz/\nAdvanced R (3e): https://adv-r.hadley.nz/\nTidyverse packages: https://www.tidyverse.org/\nreadr (fast reading/writing): https://readr.tidyverse.org/\ndplyr (data manipulation): https://dplyr.tidyverse.org/\nggplot2 (visualization): https://ggplot2.tidyverse.org/\nR Markdown (legacy): https://rmarkdown.rstudio.com/\nBase R documentation (manuals): https://cran.r-project.org/manuals.html\nRStudio IDE docs: https://docs.posit.co/ide/\nData import best practices (readr vignette): https://readr.tidyverse.org/articles/readr.html\nPalmer Penguins dataset: https://allisonhorst.github.io/palmerpenguins/\nTidyTuesday: https://github.com/rfordatascience/tidytuesday\nUCI ML Repository: https://archive.ics.uci.edu/\nKaggle datasets: https://www.kaggle.com/datasets\ndata.gov: https://data.gov/"
  },
  {
    "objectID": "04_Probability_distributions/Probability_Distributions.html",
    "href": "04_Probability_distributions/Probability_Distributions.html",
    "title": "Probability and Distributions in HEOR with R",
    "section": "",
    "text": "Abstract\nThis Quarto document reviews key probability concepts and the distributions most commonly used in Health Economics and Outcomes Research (HEOR). Through concise simulations and visualizations, we connect theory to typical HEOR tasks: event probabilities, counts of utilization, costs, time-to-event outcomes, utilities, and Bayesian updating.\nHow to use this document\n\nRun all cells to generate simulated examples for each concept/distribution.\nReplace simulated inputs with your data to see how distributional choices affect analysis.\nUse figures and tables as templates for teaching, code review, or reports.\n\nSetup\n\n# Install/load packages\npkgs &lt;- c(\"tidyverse\", \"survival\", \"broom\", \"gt\", \"scales\", \"MASS\", \"gridExtra\")\nto_install &lt;- setdiff(pkgs, rownames(installed.packages()))\nif (length(to_install) &gt; 0) install.packages(to_install, repos = \"https://cloud.r-project.org\")\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(survival)\nlibrary(broom)\nlibrary(gt)\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nlibrary(gridExtra)\n\n\nAttaching package: 'gridExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\nset.seed(2025)\ntheme_set(theme_minimal(base_size = 12))\noptions(scipen = 999)\n\n# Helper: simple Dirichlet RNG (no extra packages)\nrdirichlet &lt;- function(n, alpha) {\n  k &lt;- length(alpha)\n  x &lt;- matrix(rexp(n * k, rate = 1), nrow = n, ncol = k) # will be scaled by Gamma draws\n  for (j in 1:k) x[, j] &lt;- rgamma(n, shape = alpha[j], rate = 1)\n  x / rowSums(x)\n}\n\n\nProbability Basics\n\nKey ideas\n\nEvents and probabilities: P(A), P(B), joint P(A ∩ B), conditional P(A | B) = P(A ∩ B) / P(B).\nIndependence: A and B are independent if P(A ∩ B) = P(A)P(B).\nLaw of large numbers (LLN): sample proportions and means converge to true probabilities/expectations as n increases.\n\nExample (HEOR context)\n\nA: Monthly cost &gt; $10,000\nB: At least one inpatient admission this month\n\nWe simulate cost and admissions for many member-months and estimate P(A), P(B), P(A ∩ B), P(A)P(B), P(A | B).\n\nn_mc &lt;- 100000\nlam_admit &lt;- 0.5 # mean admits per month\ncost_meanlog &lt;- 8.1\ncost_sdlog &lt;- 0.85\n\nadmit &lt;- rpois(n_mc, lam_admit)\ncost &lt;- rlnorm(n_mc, meanlog = cost_meanlog, sdlog = cost_sdlog)\n\nA &lt;- cost &gt; 10000\nB &lt;- admit &gt;= 1\n\nest &lt;- tibble(\n  `P(A)` = mean(A),\n  `P(B)` = mean(B),\n  `P(A ∩ B)` = mean(A & B),\n  `P(A)P(B)` = mean(A) * mean(B),\n  `P(A | B)` = mean(A & B) / mean(B)\n) %&gt;% pivot_longer(everything(), names_to = \"quantity\", values_to = \"estimate\") %&gt;%\n  mutate(estimate = round(estimate, 4))\n\ngt(est) %&gt;%\n  cols_label(quantity = \"Quantity\", estimate = \"Estimate\") %&gt;%\n  tab_header(title = \"Monte Carlo Estimates of Event Probabilities (Member-Month)\")\n\n\n\n\n\n\n\nMonte Carlo Estimates of Event Probabilities (Member-Month)\n\n\nQuantity\nEstimate\n\n\n\n\nP(A)\n0.0952\n\n\nP(B)\n0.3948\n\n\nP(A ∩ B)\n0.0377\n\n\nP(A)P(B)\n0.0376\n\n\nP(A | B)\n0.0954\n\n\n\n\n\n\n\nLaw of Large Numbers demonstration\nWe track the running estimate of P(B) as sample size grows.\n\nrunning_pB &lt;- tibble(\n  n = 1:n_mc,\n  pB_hat = cumsum(B) / (1:n_mc)\n)\n\nggplot(running_pB %&gt;% filter(n %% 200 == 0), aes(n, pB_hat)) +\n  geom_line(color = \"steelblue\") +\n  geom_hline(yintercept = 1 - dpois(0, lam_admit), linetype = \"dashed\", color = \"tomato\") +\n  labs(title = \"Law of Large Numbers: Convergence of P(B) Estimate\",\n       x = \"Number of member-months\",\n       y = \"Estimated P(at least one admission)\") +\n  annotate(\"text\", x = n_mc*0.7, y = 1 - dpois(0, lam_admit) + 0.02,\n           label = \"True P(B) = 1 - P(0 admits) = 1 - e^{-λ}\", color = \"tomato\")\n\n\n\n\n\n\n\n\n\nRandom Variables, Expectation, and Variance\n\nKey ideas\n\nA random variable X has a distribution summarized by its mean E[X] and variance Var(X).\nLinear expectation: E[aX + b] = aE[X] + b; Var(aX + b) = a^2 Var(X).\nFor sums of independent variables, means add and variances add.\n\nDemonstration with simulated costs (lognormal) and admissions (Poisson):\n\nn &lt;- 50000\nX &lt;- rlnorm(n, meanlog = 8, sdlog = 0.9)  # monthly cost\nY &lt;- rpois(n, lambda = 0.7)               # monthly admits\n\nemp &lt;- tibble(\n  variable = c(\"Cost (X)\", \"Admits (Y)\"),\n  mean = c(mean(X), mean(Y)),\n  variance = c(var(X), var(Y))\n)\n\ntheo &lt;- tibble(\n  variable = c(\"Cost (X)\", \"Admits (Y)\"),\n  mean = c(exp(8 + 0.9^2/2), 0.7),\n  variance = c((exp(0.9^2) - 1) * exp(2*8 + 0.9^2), 0.7)\n)\n\ncompare &lt;- emp %&gt;%\n  left_join(theo, by = \"variable\", suffix = c(\"_empirical\", \"_theoretical\")) %&gt;%\n  mutate(across(contains(\"mean\"), round, 2),\n         across(contains(\"variance\"), round, 2))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(contains(\"mean\"), round, 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\ngt(compare) %&gt;%\n  tab_header(title = \"Empirical vs Theoretical Moments\")\n\n\n\n\n\n\n\nEmpirical vs Theoretical Moments\n\n\nvariable\nmean_empirical\nvariance_empirical\nmean_theoretical\nvariance_theoretical\n\n\n\n\nCost (X)\n4463.47\n25899221.36\n4469.36\n24927160.2\n\n\nAdmits (Y)\n0.70\n0.69\n0.70\n0.7\n\n\n\n\n\n\n\n\nBernoulli and Binomial: Binary outcomes and counts of successes\n\nCommon HEOR uses\n\nReadmission within 30 days (yes/no).\nMedication adherence threshold (PDC ≥ 80%).\nNumber of responders in a sample.\n\n\n# Bernoulli trials (readmission yes/no)\np &lt;- 0.15\nn_pat &lt;- 2000\nreadmit &lt;- rbinom(n_pat, size = 1, prob = p)\n\n# Binomial count within cohort of size m per site\nm &lt;- 50\nn_sites &lt;- 1000\nresponders_per_site &lt;- rbinom(n_sites, size = m, prob = p)\n\nsummary_tbl &lt;- tibble(\n  Quantity = c(\"Pr(readmit=1)\", \"Mean responders/site\", \"Var responders/site\"),\n  Estimate = c(mean(readmit), mean(responders_per_site), var(responders_per_site)),\n  Theoretical = c(p, m*p, m*p*(1-p))\n) %&gt;%\n  mutate(across(c(Estimate, Theoretical), round, 3))\n\ngt(summary_tbl) %&gt;%\n  tab_header(title = \"Bernoulli/Binomial: Empirical vs Theoretical\")\n\n\n\n\n\n\n\nBernoulli/Binomial: Empirical vs Theoretical\n\n\nQuantity\nEstimate\nTheoretical\n\n\n\n\nPr(readmit=1)\n0.155\n0.150\n\n\nMean responders/site\n7.416\n7.500\n\n\nVar responders/site\n6.205\n6.375\n\n\n\n\n\n\n\n\nk &lt;- 0:m\npmf &lt;- dbinom(k, size = m, prob = p)\ndf &lt;- tibble(k, pmf)\n\nmu &lt;- m*p\nsigma &lt;- sqrt(m*p*(1-p))\napprox &lt;- tibble(k, density = dnorm(k, mean = mu, sd = sigma))\n\nggplot(df, aes(k, pmf)) +\n  geom_col(fill = \"steelblue\", alpha = 0.6) +\n  geom_line(data = approx, aes(k, density), color = \"tomato\", linewidth = 1) +\n  labs(x = \"Number of responders\", y = \"Probability\")\n\n\n\n\nBinomial PMF (m=50, p=0.15) with Normal approximation.\n\n\n\n\n\nPoisson and Negative Binomial: Utilization counts and overdispersion\n\nCommon HEOR uses\n\nCounts of inpatient admissions, ED visits, office visits.\nOverdispersion (variance &gt; mean) is common; Negative Binomial often fits better than Poisson.\n\n\nn &lt;- 10000\n\n# Scenario A: Poisson (mean = variance)\nlambda &lt;- 0.8\ny_pois &lt;- rpois(n, lambda)\n\n# Scenario B: Overdispersed counts (NegBin with mean mu and size k)\nmu &lt;- 0.8\nk_size &lt;- 1.0 # smaller =&gt; more overdispersion\ny_nb &lt;- rnbinom(n, size = k_size, mu = mu)\n\nsumm &lt;- tibble(\n  scenario = c(\"Poisson\", \"NegBin\"),\n  mean = c(mean(y_pois), mean(y_nb)),\n  variance = c(var(y_pois), var(y_nb))\n)\n\ngt(summ %&gt;% mutate(across(c(mean, variance), round, 3))) %&gt;%\n  tab_header(title = \"Mean-Variance Comparison: Poisson vs Negative Binomial\")\n\n\n\n\n\n\n\nMean-Variance Comparison: Poisson vs Negative Binomial\n\n\nscenario\nmean\nvariance\n\n\n\n\nPoisson\n0.785\n0.786\n\n\nNegBin\n0.795\n1.436\n\n\n\n\n\n\n\n\ndfp &lt;- tibble(y = y_pois, dist = \"Poisson\")\ndfn &lt;- tibble(y = y_nb, dist = \"NegBin\")\ndf_all &lt;- bind_rows(dfp, dfn)\n\nggplot(df_all, aes(y, after_stat(count/sum(count)), fill = dist)) +\n  geom_histogram(binwidth = 1, position = \"dodge\", color = \"white\") +\n  scale_x_continuous(breaks = 0:7) +\n  labs(x = \"Count\", y = \"Proportion\", fill = \"Distribution\")\n\n\n\n\nDistribution of counts: Poisson vs Negative Binomial (overdispersed).\n\n\n\n\nFitting Poisson vs Negative Binomial regression to overdispersed data:\n\nset.seed(1)\nn &lt;- 5000\nx &lt;- rbinom(n, 1, 0.5)\n# True NegBin generating model\nmu &lt;- exp(-0.2 + 0.5*x)\nk_size &lt;- 1.2\ny &lt;- rnbinom(n, size = k_size, mu = mu)\n\nfit_p &lt;- glm(y ~ x, family = poisson())\nfit_nb &lt;- MASS::glm.nb(y ~ x)\n\ncoef_tbl &lt;- bind_rows(\n  tidy(fit_p) %&gt;% mutate(model = \"Poisson\"),\n  tidy(fit_nb) %&gt;% mutate(model = \"NegBin\")\n) %&gt;%\n  mutate(estimate = round(estimate, 3),\n         std.error = round(std.error, 3),\n         p.value = round(p.value, 3))\n\ngt(coef_tbl %&gt;% dplyr::select(model, term, estimate, std.error, p.value)) %&gt;%\n  tab_header(title = \"Poisson vs Negative Binomial Regression Coefficients\")\n\n\n\n\n\n\n\nPoisson vs Negative Binomial Regression Coefficients\n\n\nmodel\nterm\nestimate\nstd.error\np.value\n\n\n\n\nPoisson\n(Intercept)\n-0.225\n0.022\n0\n\n\nPoisson\nx\n0.495\n0.028\n0\n\n\nNegBin\n(Intercept)\n-0.225\n0.028\n0\n\n\nNegBin\nx\n0.495\n0.038\n0\n\n\n\n\n\n\n\n\nCost Distributions: Gamma and Lognormal\n\nCommon HEOR uses\n\nCosts are positive and right-skewed.\nGamma GLM with log link or Lognormal models are typical; two-part models when many zeros.\n\n\nn &lt;- 10000\n\n# Gamma: shape/scale parameterization\nshape &lt;- 2.2\nscale &lt;- 300\ncost_gamma &lt;- rgamma(n, shape = shape, scale = scale)\n\n# Lognormal\nmeanlog &lt;- 6.5\nsdlog &lt;- 0.9\ncost_logn &lt;- rlnorm(n, meanlog = meanlog, sdlog = sdlog)\n\ncosts &lt;- bind_rows(\n  tibble(cost = cost_gamma, model = \"Gamma\"),\n  tibble(cost = cost_logn, model = \"Lognormal\")\n)\n\nsummary_costs &lt;- costs %&gt;% group_by(model) %&gt;%\n  summarise(mean = mean(cost), sd = sd(cost), p95 = quantile(cost, 0.95), .groups = \"drop\")\n\ngt(summary_costs %&gt;% mutate(across(c(mean, sd, p95), dollar))) %&gt;%\n  tab_header(title = \"Cost Distribution Summaries\")\n\n\n\n\n\n\n\nCost Distribution Summaries\n\n\nmodel\nmean\nsd\np95\n\n\n\n\nGamma\n$665.18\n$445.18\n$1,533.41\n\n\nLognormal\n$991.66\n$1,096.49\n$2,910.83\n\n\n\n\n\n\n\n\ncap &lt;- costs %&gt;% group_by(model) %&gt;% summarise(cut = quantile(cost, 0.99), .groups = \"drop\") %&gt;% pull(cut) %&gt;% min()\nggplot(costs %&gt;% filter(cost &lt; cap), aes(cost, fill = model)) +\n  geom_density(alpha = 0.35, color = NA) +\n  scale_x_continuous(labels = dollar) +\n  labs(x = \"Cost ($)\", y = \"Density\", fill = \"Distribution\")\n\n\n\n\nCost densities (truncated at 99th percentile for visibility).\n\n\n\n\nGamma GLM example with a binary covariate:\n\nset.seed(2)\nn &lt;- 4000\ntreat &lt;- rbinom(n, 1, 0.5)\nmu &lt;- exp(6 + 0.4 * treat) # log-link mean\n# Simulate Gamma with variance proportional to mean^2\nphi &lt;- 1.2 # dispersion\nshape &lt;- 1/phi\nscale &lt;- mu * phi\ny_cost &lt;- rgamma(n, shape = shape, scale = scale)\n\nfit_gamma &lt;- glm(y_cost ~ treat, family = Gamma(link = \"log\"))\ntidy(fit_gamma, conf.int = TRUE) %&gt;%\n  mutate(across(c(estimate, conf.low, conf.high), round, 3)) %&gt;% gt() %&gt;%\n  tab_header(title = \"Gamma GLM (log link) for Costs\")\n\n\n\n\n\n\n\nGamma GLM (log link) for Costs\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n6.006\n0.02485609\n241.61508\n0.000000000000000000000000000000000000\n5.957\n6.055\n\n\ntreat\n0.413\n0.03499469\n11.79776\n0.000000000000000000000000000000133224\n0.344\n0.481\n\n\n\n\n\n\n\n\nTime-to-Event Distributions: Exponential and Weibull\n\nCommon HEOR uses\n\nTime to hospitalization, treatment discontinuation, death.\nExponential has constant hazard; Weibull allows increasing/decreasing hazard.\n\n\nset.seed(3)\nn &lt;- 3000\n\n# Exponential: rate = 0.1 per month (mean 10 months)\nrate_exp &lt;- 0.1\nt_exp &lt;- rexp(n, rate = rate_exp)\n\n# Weibull: shape &gt; 1 =&gt; increasing hazard\nshape_w &lt;- 1.5\nscale_w &lt;- 12\nt_weib &lt;- rweibull(n, shape = shape_w, scale = scale_w)\n\n# Administrative censoring at 12 months\ncensor &lt;- 12\ntime &lt;- c(t_exp, t_weib)\nevent &lt;- as.integer(time &lt;= censor)\ntime &lt;- pmin(time, censor)\ndist &lt;- rep(c(\"Exponential\", \"Weibull\"), each = n)\n\nsurv_df &lt;- tibble(time = time, event = event, dist = dist)\nfit_km &lt;- survfit(Surv(time, event) ~ dist, data = surv_df)\nkm_tidy &lt;- broom::tidy(fit_km)\n\n\n# Theoretical survival functions\ntgrid &lt;- seq(0, 12, by = 0.2)\nS_exp &lt;- exp(-rate_exp * tgrid)\nS_weib &lt;- exp(-(tgrid/scale_w)^shape_w)\ntheo &lt;- bind_rows(\n  tibble(time = tgrid, S = S_exp, dist = \"Exponential (theoretical)\"),\n  tibble(time = tgrid, S = S_weib, dist = \"Weibull (theoretical)\")\n)\n\nggplot() +\n  geom_step(data = km_tidy, aes(time, estimate, color = strata), linewidth = 1) +\n  geom_line(data = theo, aes(time, S, color = dist), linetype = \"dashed\") +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(x = \"Time (months)\", y = \"Survival\",\n       color = \"Curve\")\n\n\n\n\nKaplan–Meier curves with theoretical survival overlays.\n\n\n\n\nHazard shapes\n\nhaz_exp &lt;- tibble(time = tgrid[-1], hazard = rep(rate_exp, length(tgrid)-1), dist = \"Exponential\")\nhaz_weib &lt;- tibble(time = tgrid[-1],\n                   hazard = (shape_w/scale_w) * (tgrid[-1]/scale_w)^(shape_w - 1),\n                   dist = \"Weibull (shape 1.5)\")\n\nhaz &lt;- bind_rows(haz_exp, haz_weib)\nggplot(haz, aes(time, hazard, color = dist)) +\n  geom_line(linewidth = 1) +\n  labs(x = \"Time\", y = \"Hazard\", color = \"Distribution\")\n\n\n\n\nHazard functions: constant (Exponential) vs increasing (Weibull, shape=1.5).\n\n\n\n\n\nBeta Distribution: Probabilities and Utilities (0–1)\n\nCommon HEOR uses\n\nUtility weights and QALYs bounded in [0,1].\nProbabilities and rates, including Bayesian priors.\n\n\nx &lt;- seq(0, 1, by = 0.001)\nbeta_cfg &lt;- tribble(\n  ~alpha, ~beta, ~label,\n  2, 2, \"Beta(2,2): diffusion/prior ignorance\",\n  16, 4, \"Beta(16,4): mean 0.8, concentrated\",\n  2, 8, \"Beta(2,8): skewed low\"\n)\n\nbeta_df &lt;- beta_cfg %&gt;%\n  rowwise() %&gt;%\n  mutate(df = list(tibble(x = x, density = dbeta(x, alpha, beta)))) %&gt;%\n  unnest(df)\n\nggplot(beta_df, aes(x, density, color = label)) +\n  geom_line(linewidth = 1) +\n  labs(x = \"Value in [0,1]\", y = \"Density\", color = \"Distribution\")\n\n\n\n\nBeta distributions illustrate diverse shapes for bounded quantities.\n\n\n\n\nBayesian Beta–Binomial updating (e.g., response rate)\n\nalpha0 &lt;- 2; beta0 &lt;- 2              # prior\nn &lt;- 100; y &lt;- 30                    # 30 responses out of 100\nalpha_post &lt;- alpha0 + y\nbeta_post  &lt;- beta0 + (n - y)\n\nprior_mean &lt;- alpha0 / (alpha0 + beta0)\npost_mean  &lt;- alpha_post / (alpha_post + beta_post)\nci &lt;- qbeta(c(0.025, 0.975), alpha_post, beta_post)\n\ntab &lt;- tibble(\n  quantity = c(\"Prior mean\", \"Posterior mean\", \"95% CrI lower\", \"95% CrI upper\"),\n  value = c(prior_mean, post_mean, ci[1], ci[2])\n) %&gt;% mutate(value = round(value, 3))\n\ngt(tab) %&gt;%\n  tab_header(title = \"Beta-Binomial Update for a Response Probability\")\n\n\n\n\n\n\n\nBeta-Binomial Update for a Response Probability\n\n\nquantity\nvalue\n\n\n\n\nPrior mean\n0.500\n\n\nPosterior mean\n0.308\n\n\n95% CrI lower\n0.223\n\n\n95% CrI upper\n0.399\n\n\n\n\n\n\n\n\nMultinomial and Dirichlet: Transitions in Markov Models\n\nCommon HEOR uses\n\nMultistate models with row-wise transition probabilities.\nDirichlet prior over categorical probabilities.\n\n\nset.seed(4)\nalpha &lt;- c(10, 5, 2) # prior counts for (Healthy, Sick, Dead)\nK &lt;- 5\nrows &lt;- rdirichlet(K, alpha)\ncolnames(rows) &lt;- c(\"Healthy\", \"Sick\", \"Dead\")\ndirichlet_tbl &lt;- as_tibble(rows) %&gt;% mutate(row = row_number()) %&gt;% relocate(row)\n\ngt(dirichlet_tbl %&gt;% mutate(across(-row, ~round(.x, 3)))) %&gt;%\n  tab_header(title = \"Samples from Dirichlet(alpha = [10,5,2])\")\n\n\n\n\n\n\n\nSamples from Dirichlet(alpha = [10,5,2])\n\n\nrow\nHealthy\nSick\nDead\n\n\n\n\n1\n0.456\n0.409\n0.135\n\n\n2\n0.520\n0.412\n0.068\n\n\n3\n0.402\n0.414\n0.184\n\n\n4\n0.554\n0.346\n0.100\n\n\n5\n0.600\n0.224\n0.175\n\n\n\n\n\n\n\n\nZero-Inflated and Hurdle Models: Many Zeros in Utilization\n\nCommon HEOR uses\n\nZero-inflated counts for ED visits, admissions, or costs in short windows.\n\n\nset.seed(5)\nn &lt;- 10000\npi0 &lt;- 0.4\nlambda &lt;- 1.2\nis_struct_zero &lt;- rbinom(n, 1, pi0)\ny_zip &lt;- ifelse(is_struct_zero == 1, 0, rpois(n, lambda))\nzip_df &lt;- tibble(y = y_zip)\n\nprop_zero &lt;- mean(y_zip == 0)\nmean_y &lt;- mean(y_zip); var_y &lt;- var(y_zip)\n\nsummary_zip &lt;- tibble(\n  quantity = c(\"Proportion zeros\", \"Mean\", \"Variance\"),\n  estimate = c(prop_zero, mean_y, var_y)\n)\n\np_hist &lt;- ggplot(zip_df, aes(y, after_stat(count/sum(count)))) +\n  geom_histogram(binwidth = 1, fill = \"steelblue\", color = \"white\") +\n  scale_x_continuous(breaks = 0:8) +\n  labs(x = \"Count\", y = \"Proportion\")\n\ngridExtra::grid.arrange(\n  tableGrob(summary_zip %&gt;% mutate(estimate = round(estimate, 3))),\n  p_hist,\n  ncol = 2,\n  widths = c(0.45, 0.55)\n)\n\n\n\n\nZero-Inflated Poisson (π=0.4, λ=1.2) produces excess zeros and overdispersion.\n\n\n\n\n\nLinking Distributions to HEOR Modeling Choices\n\n\nBinary outcomes: Bernoulli/Binomial; logistic regression (logit link).\nCounts: Poisson (log link) if variance ≈ mean; Negative Binomial for overdispersion.\nCosts: Gamma (log link) or Lognormal; two-part/hurdle when many zeros.\nTime-to-event: Exponential (constant hazard), Weibull (flexible hazard), Cox (semiparametric).\nProbabilities/utilities: Beta; transition vectors: Dirichlet/Multinomial.\nZero inflation: Zero-inflated Poisson/NegBin; hurdle models.\n\nAppendix A: Central Limit Theorem (CLT) example\nEven with skewed costs, sample means are approximately normal for large n.\n\nset.seed(6)\nn_samples &lt;- 10000\nsample_size &lt;- 50\ncost &lt;- rlnorm(1e6, meanlog = 6.7, sdlog = 1.0)\nidx &lt;- matrix(sample.int(length(cost), n_samples * sample_size, replace = TRUE), ncol = sample_size)\nmeans &lt;- rowMeans(matrix(cost[idx], ncol = sample_size, byrow = TRUE))\nggplot(tibble(x = means), aes(x)) +\n  geom_histogram(aes(y = ..density..), bins = 50, fill = \"steelblue\", color = \"white\") +\n  geom_density(color = \"tomato\", linewidth = 1) +\n  labs(title = \"Distribution of Sample Means of Skewed Costs (n=50 per sample)\",\n       x = \"Sample mean cost\", y = \"Density\")\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\n\nAppendix B: Quick Reference — Theoretical Moments\n\nref &lt;- tribble(\n  ~Distribution, ~Parameters, ~Mean, ~Variance,\n  \"Bernoulli\", \"p\", \"p\", \"p(1-p)\",\n  \"Binomial\", \"n, p\", \"np\", \"np(1-p)\",\n  \"Poisson\", \"λ\", \"λ\", \"λ\",\n  \"NegBin (mean μ, size k)\", \"μ, k\", \"μ\", \"μ + μ^2/k\",\n  \"Exponential\", \"rate λ\", \"1/λ\", \"1/λ^2\",\n  \"Weibull\", \"shape k, scale λ\", \"λ Γ(1+1/k)\", \"λ^2[Γ(1+2/k)-Γ(1+1/k)^2]\",\n  \"Gamma\", \"shape α, scale θ\", \"αθ\", \"αθ^2\",\n  \"Lognormal\", \"μ, σ\", \"exp(μ+σ^2/2)\", \"(exp(σ^2)-1)exp(2μ+σ^2)\",\n  \"Beta\", \"α, β\", \"α/(α+β)\", \"αβ/[(α+β)^2(α+β+1)]\"\n)\n\ngt(ref) %&gt;%\n  tab_header(title = \"Selected Distributions and Their Moments\")\n\n\n\n\n\n\n\nSelected Distributions and Their Moments\n\n\nDistribution\nParameters\nMean\nVariance\n\n\n\n\nBernoulli\np\np\np(1-p)\n\n\nBinomial\nn, p\nnp\nnp(1-p)\n\n\nPoisson\nλ\nλ\nλ\n\n\nNegBin (mean μ, size k)\nμ, k\nμ\nμ + μ^2/k\n\n\nExponential\nrate λ\n1/λ\n1/λ^2\n\n\nWeibull\nshape k, scale λ\nλ Γ(1+1/k)\nλ^2[Γ(1+2/k)-Γ(1+1/k)^2]\n\n\nGamma\nshape α, scale θ\nαθ\nαθ^2\n\n\nLognormal\nμ, σ\nexp(μ+σ^2/2)\n(exp(σ^2)-1)exp(2μ+σ^2)\n\n\nBeta\nα, β\nα/(α+β)\nαβ/[(α+β)^2(α+β+1)]\n\n\n\n\n\n\n\nBest Practices\n\nInspect mean-variance relationships to pick appropriate count models.\nExamine skewness for costs; consider log transforms, Gamma GLMs, or two-part models.\nFor survival data, choose parametric distributions that match plausible hazards; validate with KM overlays.\nFor probabilities and utilities in [0,1], consider Beta distributions; use conjugate priors for transparent Bayesian updates.\nAlways perform model diagnostics and sensitivity analyses; document assumptions.\n\nSession Info\n\nsessionInfo()\n\nR version 4.4.3 (2025-02-28)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.3.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] gridExtra_2.3   MASS_7.3-64     scales_1.4.0    gt_1.0.0       \n [5] broom_1.0.8     survival_3.8-3  lubridate_1.9.4 forcats_1.0.0  \n [9] stringr_1.5.1   dplyr_1.1.4     purrr_1.0.4     readr_2.1.5    \n[13] tidyr_1.3.1     tibble_3.3.0    ggplot2_3.5.2   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] sass_0.4.10        generics_0.1.4     xml2_1.3.8         stringi_1.8.7     \n [5] lattice_0.22-6     hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n [9] evaluate_1.0.4     grid_4.4.3         timechange_0.3.0   RColorBrewer_1.1-3\n[13] fastmap_1.2.0      jsonlite_2.0.0     Matrix_1.7-2       backports_1.5.0   \n[17] cli_3.6.5          rlang_1.1.6        splines_4.4.3      withr_3.0.2       \n[21] yaml_2.3.10        tools_4.4.3        tzdb_0.5.0         vctrs_0.6.5       \n[25] R6_2.6.1           lifecycle_1.0.4    htmlwidgets_1.6.4  pkgconfig_2.0.3   \n[29] pillar_1.10.2      gtable_0.3.6       glue_1.8.0         xfun_0.52         \n[33] tidyselect_1.2.1   rstudioapi_0.17.1  knitr_1.50         farver_2.1.2      \n[37] htmltools_0.5.8.1  rmarkdown_2.29     labeling_0.4.3     compiler_4.4.3"
  },
  {
    "objectID": "00_R_basics/R basics/R_basics.html",
    "href": "00_R_basics/R basics/R_basics.html",
    "title": "Getting Started with R",
    "section": "",
    "text": "Introduction\n\nThis guide shows how to:\n\nDownload and install R and RStudio\nUnderstand how base R differs from RStudio\nNavigate the RStudio environment (the 4 panes)\nFormat flat files (like CSV) for loading\nLoad a dataset (flat file and pointers to other resources)\nInstall and load libraries\nCreate objects\nConduct basic analyses\nSave datasets\nSave R Markdown and Quarto files\n\n\n\n1 Download and Install R and RStudio\n\nR is the programming language. RStudio (by Posit) is a popular Integrated Development Environment (IDE) for R.\nInstall R first, then RStudio.\n\nSteps\n\nDownload R (CRAN):\n\n\nhttps://cran.r-project.org/\nClick “Download R for Windows” or “macOS” or “Linux”\nChoose the latest release, then run the installer\n\n\nDownload RStudio Desktop (free):\n\n\nhttps://posit.co/download/rstudio-desktop/\nDownload the installer for your OS and run it\nOpen RStudio after installing (R should already be installed)\n\nCheck versions\n\nR.version.string\n\n[1] \"R version 4.4.3 (2025-02-28)\"\n\n# If running inside RStudio, this may show RStudio version:\nif (exists(\"RStudio.Version\")) {\n  try({\n    v &lt;- RStudio.Version()\n    paste(\"RStudio version:\", v$version)\n  }, silent = TRUE)\n}\n\n\n\n2 How Base R Differs from RStudio\n\nBase R\n\nThe language + interpreter/engine\nComes with a console and basic GUI (varies by OS)\nYou can run scripts and commands via the R console or terminal\n\nRStudio IDE (by Posit)\n\nA graphical environment wrapping R\nOffers script editor, plotting viewer, environment browser, package manager, project management, and integrated help\nMakes development, reproducibility, and visualization easier, but does not replace R itself\n\n\nExample: Base R functionality (works the same in RStudio since RStudio calls R under the hood)\n\n# Base R calculations\nx &lt;- c(1, 2, 3, 4, 5)\nmean(x)\n\n[1] 3\n\nsd(x)\n\n[1] 1.581139\n\nsum(x^2)\n\n[1] 55\n\n\n\n\n3 Introduction to the RStudio Environment (The 4 Panes)\n\nSource (top-left, by default)\n\nYour editor for .R scripts, .Rmd, .qmd files\nRun code lines or chunks into the Console\n\nConsole (bottom-left)\n\nWhere R commands execute\nShows outputs, errors, warnings\n\nEnvironment/History (top-right)\n\nEnvironment: objects currently in memory\nHistory: previously run commands\n\nFiles/Plots/Packages/Help/Viewer (bottom-right)\n\nFiles: browse project files\nPlots: view figures\nPackages: installed packages and load/unload controls\nHelp: documentation for functions and packages\nViewer: renders HTML content (e.g., Quarto docs)\n\n\n\n\n\nRStudio window\n\n\nQuick demonstrations\n\n# Create a few objects (watch the Environment pane update)\nnums &lt;- rnorm(10)\ndf &lt;- data.frame(id = 1:5, value = c(10, 20, 15, 30, NA))\n\n# Use Help pane: open documentation\nhelp(\"mean\")   # or ?mean\n\n# Show a basic plot (appears in Plots tab)\nplot(nums, type = \"b\", main = \"Demo plot\", xlab = \"Index\", ylab = \"Value\")\n\n\n\n\n\n\n\n\n\n\n4 Formatting Flat Files for Loading\nGood practices for CSV/TSV flat files\n\nUse a header row with short, clear, alphanumeric column names (avoid spaces; use underscores if needed)\nUse UTF-8 encoding\nUse a consistent delimiter (comma for CSV, tab for TSV)\nRepresent missing values consistently (e.g., empty cell or NA; avoid mixed values like “-”, “N/A”, “null”)\nUse ISO 8601 for dates (YYYY-MM-DD) and include time zones if timestamps are present\nAvoid embedded line breaks in cells; if present, ensure proper quoting\nKeep one “tidy” table per file: each row is one observation, each column is one variable\n\nCreate and save a well-formatted CSV\n\n# Example tidy dataset\ntidy_example &lt;- data.frame(\n  subject_id = 1:6,\n  group = c(\"control\", \"control\", \"control\", \"treatment\", \"treatment\", \"treatment\"),\n  age_years = c(34, 45, 51, 29, 40, NA),\n  visit_date = as.Date(c(\"2025-01-10\", \"2025-01-12\", \"2025-01-13\", \"2025-01-11\", \"2025-01-12\", \"2025-01-14\")),\n  score = c(87, 90, 85, 92, 88, 91)\n)\n\n# Create a data folder, then save CSV\ndir.create(\"data\", showWarnings = FALSE)\ncsv_path &lt;- file.path(\"data\", \"tidy_example.csv\")\nwrite.csv(tidy_example, csv_path, row.names = FALSE, na = \"\")\ncsv_path\n\n[1] \"data/tidy_example.csv\"\n\n\n\n\n5 Loading a Dataset (Flat File and Other Resources)\nLoad the CSV using base R\n\nloaded_base &lt;- read.csv(csv_path, stringsAsFactors = FALSE)\nstr(loaded_base)\n\n'data.frame':   6 obs. of  5 variables:\n $ subject_id: int  1 2 3 4 5 6\n $ group     : chr  \"control\" \"control\" \"control\" \"treatment\" ...\n $ age_years : int  34 45 51 29 40 NA\n $ visit_date: chr  \"2025-01-10\" \"2025-01-12\" \"2025-01-13\" \"2025-01-11\" ...\n $ score     : int  87 90 85 92 88 91\n\nhead(loaded_base)\n\n\n  \n\n\n\nLoad the CSV using readr (tidyverse) for better performance and type control\n\n# Install readr if needed (run once; eval is FALSE so it won't execute automatically)\n# install.packages(\"readr\")\n\n\n# If readr is available, demonstrate its use safely\nif (requireNamespace(\"readr\", quietly = TRUE)) {\n  loaded_readr &lt;- readr::read_csv(csv_path, show_col_types = FALSE)\n  print(loaded_readr)\n}\n\n# A tibble: 6 × 5\n  subject_id group     age_years visit_date score\n       &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;date&gt;     &lt;dbl&gt;\n1          1 control          34 2025-01-10    87\n2          2 control          45 2025-01-12    90\n3          3 control          51 2025-01-13    85\n4          4 treatment        29 2025-01-11    92\n5          5 treatment        40 2025-01-12    88\n6          6 treatment        NA 2025-01-14    91\n\n\nHandling column types and missing values explicitly with readr\n\nif (requireNamespace(\"readr\", quietly = TRUE)) {\n  loaded_typed &lt;- readr::read_csv(\n    csv_path,\n    col_types = readr::cols(\n      subject_id = readr::col_integer(),\n      group = readr::col_factor(levels = c(\"control\", \"treatment\")),\n      age_years = readr::col_double(),\n      visit_date = readr::col_date(),\n      score = readr::col_double()\n    ),\n    show_col_types = FALSE\n  )\n  str(loaded_typed)\n}\n\nspc_tbl_ [6 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ subject_id: int [1:6] 1 2 3 4 5 6\n $ group     : Factor w/ 2 levels \"control\",\"treatment\": 1 1 1 2 2 2\n $ age_years : num [1:6] 34 45 51 29 40 NA\n $ visit_date: Date[1:6], format: \"2025-01-10\" \"2025-01-12\" ...\n $ score     : num [1:6] 87 90 85 92 88 91\n - attr(*, \"spec\")=\n  .. cols(\n  ..   subject_id = col_integer(),\n  ..   group = col_factor(levels = c(\"control\", \"treatment\"), ordered = FALSE, include_na = FALSE),\n  ..   age_years = col_double(),\n  ..   visit_date = col_date(format = \"\"),\n  ..   score = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nReading Excel files\n\n# install.packages(\"readxl\")  # run once\nif (requireNamespace(\"readxl\", quietly = TRUE)) {\n  # Example: readxl::read_excel(\"data/example.xlsx\", sheet = 1)\n  # (We won’t read here unless a file exists)\n}\n\nNULL\n\n\nOther dataset resources\n\nBuilt-in datasets: datasets::mtcars, iris, airquality\nPublic datasets:\n\npalmerpenguins: https://allisonhorst.github.io/palmerpenguins/\nTidyTuesday datasets: https://github.com/rfordatascience/tidytuesday\nUCI Machine Learning Repository: https://archive.ics.uci.edu/\nKaggle: https://www.kaggle.com/datasets\ndata.gov (US): https://data.gov/\nWorld Bank Data: https://data.worldbank.org/\n\n\n\n\n6 Installing and Loading Libraries\nInstall packages (run once; do not run inside production pipelines without a lockfile)\n\n# Example install (set eval: false to avoid automatic install)\n# install.packages(c(\"tidyverse\", \"readr\", \"dplyr\", \"ggplot2\", \"readxl\", \"data.table\"))\n\nLoad packages\n\n# Load if available; fall back gracefully if not\nloaded_pkgs &lt;- c()\nfor (pkg in c(\"dplyr\", \"ggplot2\")) {\n  if (requireNamespace(pkg, quietly = TRUE)) {\n    library(pkg, character.only = TRUE)\n    loaded_pkgs &lt;- c(loaded_pkgs, pkg)\n  }\n}\nloaded_pkgs\n\n[1] \"dplyr\"   \"ggplot2\"\n\n\nNotes\n\nUse install.packages(“packagename”) once per machine or project\nUse library(packagename) in each session/script where needed\nConsider project environments for reproducibility (e.g., renv)\n\n\n\n7 Creating Objects\nBasic objects\n\n# Numeric and character vectors\na &lt;- c(10, 20, 30)\nb &lt;- c(\"alpha\", \"beta\", \"gamma\")\n\n# Factors\ngrp &lt;- factor(c(\"control\", \"treatment\", \"control\"), levels = c(\"control\", \"treatment\"))\n\n# Matrices\nm &lt;- matrix(1:9, nrow = 3)\n\n# Lists (heterogeneous containers)\nmy_list &lt;- list(nums = a, labels = b, flag = TRUE)\n\n# Data frames (tabular)\ndf2 &lt;- data.frame(id = 1:3, group = grp, score = c(88, 92, 85))\nstr(df2)\n\n'data.frame':   3 obs. of  3 variables:\n $ id   : int  1 2 3\n $ group: Factor w/ 2 levels \"control\",\"treatment\": 1 2 1\n $ score: num  88 92 85\n\n# Functions\nadd_two &lt;- function(x) x + 2\nadd_two(5)\n\n[1] 7\n\n\n\n\n8 Conducting Analyses\nDescriptive statistics (base R)\n\nx &lt;- rnorm(100, mean = 50, sd = 10)\nsummary(x)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  25.69   46.25   52.15   51.95   58.40   84.53 \n\nmean(x); median(x); sd(x); quantile(x, probs = c(0.25, 0.5, 0.75))\n\n[1] 51.94926\n\n\n[1] 52.14735\n\n\n[1] 10.30833\n\n\n     25%      50%      75% \n46.25421 52.14735 58.40069 \n\n\nGroup-wise summaries (dplyr, if available)\n\nif (requireNamespace(\"dplyr\", quietly = TRUE)) {\n  library(dplyr)\n  loaded_base %&gt;%\n    group_by(group) %&gt;%\n    summarise(\n      n = n(),\n      mean_score = mean(score, na.rm = TRUE),\n      mean_age = mean(age_years, na.rm = TRUE)\n    )\n}\n\n\n  \n\n\n\nVisualization (ggplot2, if available)\n\nif (requireNamespace(\"ggplot2\", quietly = TRUE)) {\n  library(ggplot2)\n  ggplot(loaded_base, aes(x = group, y = score, fill = group)) +\n    geom_boxplot() +\n    geom_jitter(width = 0.1, alpha = 0.6) +\n    labs(title = \"Scores by Group\", x = \"Group\", y = \"Score\") +\n    theme_minimal()\n}\n\n\n\n\n\n\n\n\nLinear regression\n\n# Fit a simple model on built-in mtcars dataset\nfit &lt;- lm(mpg ~ wt + cyl, data = mtcars)\nsummary(fit)\n\n\nCall:\nlm(formula = mpg ~ wt + cyl, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.2893 -1.5512 -0.4684  1.5743  6.1004 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  39.6863     1.7150  23.141  &lt; 2e-16 ***\nwt           -3.1910     0.7569  -4.216 0.000222 ***\ncyl          -1.5078     0.4147  -3.636 0.001064 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.568 on 29 degrees of freedom\nMultiple R-squared:  0.8302,    Adjusted R-squared:  0.8185 \nF-statistic: 70.91 on 2 and 29 DF,  p-value: 6.809e-12\n\n\nT-test (group comparison)\n\n# Compare mpg for automatic vs manual transmissions\nt.test(mpg ~ am, data = mtcars)\n\n\n    Welch Two Sample t-test\n\ndata:  mpg by am\nt = -3.7671, df = 18.332, p-value = 0.001374\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -11.280194  -3.209684\nsample estimates:\nmean in group 0 mean in group 1 \n       17.14737        24.39231 \n\n\nContingency table and chi-squared test\n\ntbl &lt;- table(mtcars$cyl, mtcars$gear)\ntbl\n\n   \n     3  4  5\n  4  1  8  2\n  6  2  4  1\n  8 12  0  2\n\nchisq.test(tbl)\n\n\n    Pearson's Chi-squared test\n\ndata:  tbl\nX-squared = 18.036, df = 4, p-value = 0.001214\n\n\n\n\n9 Saving Datasets\nSave to CSV (portable)\n\n# Save mtcars as CSV\nout_csv &lt;- file.path(\"data\", \"mtcars_export.csv\")\ndir.create(\"data\", showWarnings = FALSE)\nwrite.csv(mtcars, out_csv, row.names = FALSE)\nout_csv\n\n[1] \"data/mtcars_export.csv\"\n\n\nSave to RDS (preserves R types precisely, single object)\n\nout_rds &lt;- file.path(\"data\", \"mtcars.rds\")\nsaveRDS(mtcars, out_rds)\n# Load back\nmtcars_loaded &lt;- readRDS(out_rds)\nidentical(mtcars, mtcars_loaded)\n\n[1] TRUE\n\n\nSave multiple objects to .RData (workspace-like)\n\nout_rdata &lt;- file.path(\"data\", \"analysis_objects.RData\")\nobj1 &lt;- 123\nobj2 &lt;- data.frame(x = 1:3, y = c(\"a\", \"b\", \"c\"))\nsave(obj1, obj2, file = out_rdata)\n# Load back\nrm(obj1, obj2)\nload(out_rdata)\nobj1; obj2\n\n[1] 123\n\n\n\n  \n\n\n\n\n\n10 Saving R Markdown and Quarto Files\nSaving files\n\nIn RStudio:\n\nFile -&gt; New File -&gt; Quarto Document\nFile -&gt; Save (choose .qmd extension)\nFor R Markdown: File -&gt; New File -&gt; R Markdown, then Save as .Rmd\n\n\nRendering (turn .qmd or .Rmd into HTML/PDF/Word)\n\n# Quarto render (requires Quarto installed)\n# install.packages(\"quarto\") is not needed; Quarto is a separate tool you install from https://quarto.org/\n# From R you can call:\nif (requireNamespace(\"quarto\", quietly = TRUE)) {\n  # quarto::quarto_render(\"your_document.qmd\")\n}\n\nNULL\n\n\n\n# R Markdown render (requires rmarkdown package)\n# install.packages(\"rmarkdown\")  # run once\nif (requireNamespace(\"rmarkdown\", quietly = TRUE)) {\n  # rmarkdown::render(\"your_document.Rmd\", output_format = \"html_document\")\n}\n\nNULL\n\n\nCommand-line rendering (outside R)\n\nQuarto:\n\nInstall Quarto: https://quarto.org/docs/get-started/\nIn a terminal: quarto render your_document.qmd\n\nR Markdown (legacy):\n\nIn RStudio: click “Knit”\nOr in R: rmarkdown::render(“your_document.Rmd”)\n\n\nExport formats\n\nHTML (default), PDF (requires LaTeX), Word (docx)\nChoose output format in the YAML header or via render arguments\n\n\n\n11 Sources and Further Reading\n\nR (CRAN) downloads: https://cran.r-project.org/\nRStudio Desktop by Posit: https://posit.co/download/rstudio-desktop/\nQuarto documentation: https://quarto.org/docs/\nR for Data Science (2e): https://r4ds.hadley.nz/\nAdvanced R (3e): https://adv-r.hadley.nz/\nTidyverse packages: https://www.tidyverse.org/\nreadr (fast reading/writing): https://readr.tidyverse.org/\ndplyr (data manipulation): https://dplyr.tidyverse.org/\nggplot2 (visualization): https://ggplot2.tidyverse.org/\nR Markdown (legacy): https://rmarkdown.rstudio.com/\nBase R documentation (manuals): https://cran.r-project.org/manuals.html\nRStudio IDE docs: https://docs.posit.co/ide/\nData import best practices (readr vignette): https://readr.tidyverse.org/articles/readr.html\nPalmer Penguins dataset: https://allisonhorst.github.io/palmerpenguins/\nTidyTuesday: https://github.com/rfordatascience/tidytuesday\nUCI ML Repository: https://archive.ics.uci.edu/\nKaggle datasets: https://www.kaggle.com/datasets\ndata.gov: https://data.gov/"
  },
  {
    "objectID": "01_Introduction/Introduction.html",
    "href": "01_Introduction/Introduction.html",
    "title": "Introduction to Data Science in Health Economics and Outcomes Research (HEOR) with R",
    "section": "",
    "text": "Abstract\nThis Quarto document introduces common data structures and analyses in Health Economics and Outcomes Research (HEOR), focusing on administrative claims and electronic health records (EHR). You will see all code, plots, and tables to understand exactly what each step does. All data are synthetic and for demonstration only.\nHow to use this document\n\nRun as-is to generate a synthetic dataset, descriptive tables, and plots.\nReplace the simulated data with your own claims or EHR extracts to adapt the analyses.\nUse the cross-references to orient to figures and tables as you explore.\n\nSetup\n\n# Install/load packages (suppress install messages for readability)\npkgs &lt;- c(\"tidyverse\", \"lubridate\", \"survival\", \"broom\", \"gt\", \"glue\", \"scales\")\nto_install &lt;- setdiff(pkgs, rownames(installed.packages()))\nif (length(to_install) &gt; 0) install.packages(to_install, repos = \"https://cloud.r-project.org\")\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(survival)\nlibrary(broom)\nlibrary(gt)\nlibrary(glue)\nlibrary(scales)\n\nset.seed(1234)\ntheme_set(theme_minimal(base_size = 12))\noptions(scipen = 999)  # friendlier numbers\n\nOverview\n\nData domains\n\nClaims: costs, utilization (member-month level)\nEHR: clinical measures (e.g., labs/vitals) over time\n\nAnalyses\n\nDescriptive statistics (baseline)\nCost and utilization analyses\nLogistic and count models (readmissions, admissions)\nSurvival analysis (time to first hospitalization)\nLinking EHR markers to cost outcomes\n\n\nSimulate HEOR-like Data\nWe simulate a cohort with treatment assignment, comorbidity, and outcomes; a member-month claims file; and quarterly EHR labs.\n\n# Cohort\nN &lt;- 2000\npatients &lt;- tibble(\n  id = 1:N,\n  sex = sample(c(\"Female\", \"Male\"), N, replace = TRUE, prob = c(0.55, 0.45)),\n  age = pmax(18, round(rnorm(N, mean = 62, sd = 12))),\n  treatment = sample(c(\"NewDrug\", \"StandardCare\"), N, replace = TRUE, prob = c(0.5, 0.5)),\n  index_date = as.Date(\"2022-01-01\") + sample(0:60, N, replace = TRUE),\n  comorbidity = rpois(N, lambda = 2)\n) %&gt;%\n  mutate(\n    age_std = (age - 62) / 10,\n    a1c_baseline = pmin(pmax(rnorm(N, 7.4 + 0.2 * comorbidity, 1.0), 5), 12),\n    sbp_baseline = rnorm(N, 135 + 2 * comorbidity + 0.2 * (age - 62), 10)\n  )\n\n# Time to first hospitalization (months)\nbase_hazard &lt;- 0.08\nlp &lt;- with(patients, -0.30 * (treatment == \"NewDrug\") + 0.15 * comorbidity + 0.01 * (age - 62))\nrate &lt;- base_hazard * exp(lp)\nt_event_cont &lt;- rexp(N, rate = rate)    # months\nt_event_m &lt;- ceiling(t_event_cont)\nevent &lt;- as.integer(t_event_m &lt;= 12)\nfollow_up &lt;- pmin(t_event_m, 12)\n\npatients &lt;- patients %&gt;%\n  mutate(time_to_event_m = t_event_m,\n         event = event,\n         follow_up_m = follow_up)\n\n# 30-day readmission (binary outcome)\np_readmit30 &lt;- with(patients, plogis(-2 + 0.35 * comorbidity + 0.1 * age_std + 0.25 * (treatment == \"StandardCare\")))\npatients &lt;- patients %&gt;% mutate(readmit30 = rbinom(n(), 1, p_readmit30))\n\n# Claims: member-month costs and utilization\nclaims_long &lt;- patients %&gt;%\n  mutate(n_months = 12L) %&gt;%\n  tidyr::uncount(n_months, .id = \"month_row\") %&gt;%\n  group_by(id) %&gt;%\n  mutate(month = row_number()) %&gt;%\n  ungroup() %&gt;%\n  mutate(\n    meanlog = 8 + 0.14 * comorbidity + 0.06 * age_std + 0.08 * (treatment == \"StandardCare\") + 0.01 * month,\n    cost = rlnorm(n(), meanlog = meanlog, sdlog = 0.7),\n    event_boost = case_when(\n      (month == time_to_event_m) & (event == 1) ~ 1.0,\n      abs(month - time_to_event_m) == 1 & (event == 1) ~ 0.5,\n      TRUE ~ 0\n    ),\n    cost = cost * (1 + event_boost),\n    office_visits = rpois(n(), lambda = pmax(0.1, 0.8 + 0.2 * comorbidity + 0.1 * (treatment == \"NewDrug\"))),\n    ip_admit = rbinom(n(), 1, prob = plogis(-3 + 0.5 * comorbidity + 0.8 * ((month == time_to_event_m) & (event == 1))))\n  )\n\nclaims_agg &lt;- claims_long %&gt;%\n  group_by(id) %&gt;%\n  summarise(\n    total_cost = sum(cost),\n    pmpm = mean(cost),\n    total_visits = sum(office_visits),\n    total_admits = sum(ip_admit),\n    months = n(),\n    .groups = \"drop\"\n  ) %&gt;%\n  left_join(patients %&gt;% select(id, treatment, sex, age, comorbidity, follow_up_m, event, readmit30), by = \"id\")\n\n# EHR: quarterly labs/vitals (0, 3, 6, 9 months)\nehr &lt;- patients %&gt;%\n  mutate(n_visits = 4L) %&gt;%\n  tidyr::uncount(n_visits, .id = \"visit_order\") %&gt;%\n  group_by(id) %&gt;%\n  mutate(day = c(0, 90, 180, 270)[row_number()],\n         date = index_date + days(day)) %&gt;%\n  ungroup() %&gt;%\n  mutate(\n    a1c = pmin(pmax(a1c_baseline + if_else(treatment == \"NewDrug\", -0.8 * (day / 270), -0.3 * (day / 270)) + rnorm(n(), 0, 0.3), 5), 12),\n    sbp = sbp_baseline + if_else(treatment == \"NewDrug\", -3 * (day / 270), -1 * (day / 270)) + rnorm(n(), 0, 4)\n  )\n\n# Quick peek (first few rows)\nhead(patients)\n\n\n  \n\n\nhead(claims_long)\n\n\n  \n\n\nhead(ehr)\n\n\n  \n\n\n\nCohort and Baseline Descriptives\nWe summarize demographics and comorbidity by treatment. See Table 1.\n#```{r tbl-baseline, tbl.cap=“Baseline characteristics by treatment group”}\n\ndesc &lt;- patients %&gt;%\n  transmute(\n    treatment,\n    age,\n    female = as.integer(sex == \"Female\"),\n    comorbidity\n  ) %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(\n    n = n(),\n    age_mean = mean(age),\n    age_sd = sd(age),\n    female_pct = mean(female) * 100,\n    comorb_mean = mean(comorbidity),\n    .groups = \"drop\"\n  )\n\ngt(desc) %&gt;%\n  fmt_number(columns = c(age_mean, age_sd, comorb_mean), decimals = 1) %&gt;%\n  fmt_number(columns = c(female_pct), decimals = 1) %&gt;%\n  cols_label(\n    treatment = \"Treatment\",\n    n = \"N\",\n    age_mean = \"Age (mean)\",\n    age_sd = \"Age (SD)\",\n    female_pct = \"Female (%)\",\n    comorb_mean = \"Comorbidity (mean)\"\n  ) %&gt;%\n  tab_header(\n    title = md(\"Table 1. Baseline Characteristics by Treatment\")\n  ) %&gt;%\n  tab_source_note(md(\"All values are synthetic.\"))\n\n\n\n\n\n\n\nTable 1. Baseline Characteristics by Treatment\n\n\nTreatment\nN\nAge (mean)\nAge (SD)\nFemale (%)\nComorbidity (mean)\n\n\n\n\nNewDrug\n1013\n62.5\n12.1\n54.6\n2.0\n\n\nStandardCare\n987\n62.0\n11.8\n56.2\n2.0\n\n\n\nAll values are synthetic.\n\n\n\n\n\n\n\n\nClaims: Cost and Utilization\nWe examine PMPM costs and monthly utilization. See Figure 1 and Figure 2.\n\nggplot(claims_agg, aes(x = pmpm, fill = treatment)) +\n  geom_density(alpha = 0.35, color = NA) +\n  geom_vline(data = claims_agg %&gt;% group_by(treatment) %&gt;% summarise(med = median(pmpm)),\n             aes(xintercept = med, color = treatment), linetype = \"dashed\") +\n  coord_cartesian(xlim = c(0, quantile(claims_agg$pmpm, 0.99))) +\n  scale_x_continuous(labels = dollar) +\n  labs(x = \"PMPM ($)\", y = \"Density\", fill = \"Treatment\", color = \"Treatment\",\n       subtitle = \"Dashed lines indicate within-group medians\")\n\n\n\n\nDistribution of PMPM costs by treatment (truncated at 99th percentile).\n\n\n\n\n\nmonthly_summary &lt;- claims_long %&gt;%\n  group_by(month, treatment) %&gt;%\n  summarise(mean_cost = mean(cost), mean_visits = mean(office_visits), .groups = \"drop\")\n\np_cost &lt;- ggplot(monthly_summary, aes(month, mean_cost, color = treatment)) +\n  geom_line(linewidth = 1) +\n  scale_y_continuous(labels = dollar) +\n  labs(title = \"Mean Monthly Cost\", x = \"Month since index\", y = \"Mean cost ($)\", color = \"Treatment\")\n\np_visits &lt;- ggplot(monthly_summary, aes(month, mean_visits, color = treatment)) +\n  geom_line(linewidth = 1) +\n  labs(title = \"Mean Monthly Office Visits\", x = \"Month since index\", y = \"Mean visits\", color = \"Treatment\")\n\np_cost\n\n\n\n\nMean monthly cost and mean monthly office visits by treatment.\n\n\n\np_visits\n\n\n\n\nMean monthly cost and mean monthly office visits by treatment.\n\n\n\n\nStatistical Models on Claims\nWe model inpatient admissions (count outcome) and 30-day readmission (binary outcome). See Table 2 and Table 3.\n\nfit_pois &lt;- glm(\n  total_admits ~ treatment + age + sex + comorbidity + offset(log(months)),\n  family = poisson(),\n  data = claims_agg\n)\n\nirr &lt;- tidy(fit_pois, exponentiate = TRUE, conf.int = TRUE) %&gt;%\n  mutate(across(c(estimate, conf.low, conf.high), ~round(.x, 2))) %&gt;%\n  mutate(term = recode(term,\n                       \"(Intercept)\" = \"Intercept\",\n                       \"treatmentNewDrug\" = \"Treatment: NewDrug (vs StandardCare)\",\n                       \"age\" = \"Age (per year)\",\n                       \"sexMale\" = \"Male (vs Female)\",\n                       \"comorbidity\" = \"Comorbidity (per unit)\"))\n\ngt(irr) %&gt;%\n  cols_label(term = \"Term\", estimate = \"IRR\", conf.low = \"Lower 95% CI\", conf.high = \"Upper 95% CI\", p.value = \"p-value\") %&gt;%\n  tab_header(title = md(\"Table 2. Poisson Model for Inpatient Admissions\")) %&gt;%\n  fmt_number(columns = p.value, decimals = 3)\n\n\n\n\n\n\n\nTable 2. Poisson Model for Inpatient Admissions\n\n\nTerm\nIRR\nstd.error\nstatistic\np-value\nLower 95% CI\nUpper 95% CI\n\n\n\n\nIntercept\n0.07\n0.095606559\n-28.37217251\n0.000\n0.05\n0.08\n\n\ntreatmentStandardCare\n1.00\n0.033636477\n-0.06755887\n0.946\n0.93\n1.07\n\n\nAge (per year)\n1.00\n0.001392957\n-1.55290964\n0.120\n1.00\n1.00\n\n\nMale (vs Female)\n1.00\n0.033807177\n-0.01236283\n0.990\n0.94\n1.07\n\n\nComorbidity (per unit)\n1.46\n0.009985304\n37.84055836\n0.000\n1.43\n1.49\n\n\n\n\n\n\n\n\nfit_log &lt;- glm(readmit30 ~ treatment + age + sex + comorbidity, data = patients, family = binomial())\nor &lt;- tidy(fit_log, exponentiate = TRUE, conf.int = TRUE) %&gt;%\n  mutate(across(c(estimate, conf.low, conf.high), ~round(.x, 2))) %&gt;%\n  mutate(term = recode(term,\n                       \"(Intercept)\" = \"Intercept\",\n                       \"treatmentNewDrug\" = \"Treatment: NewDrug (vs StandardCare)\",\n                       \"age\" = \"Age (per year)\",\n                       \"sexMale\" = \"Male (vs Female)\",\n                       \"comorbidity\" = \"Comorbidity (per unit)\"))\n\ngt(or) %&gt;%\n  cols_label(term = \"Term\", estimate = \"OR\", conf.low = \"Lower 95% CI\", conf.high = \"Upper 95% CI\", p.value = \"p-value\") %&gt;%\n  tab_header(title = md(\"Table 3. Logistic Model for 30-day Readmission\")) %&gt;%\n  fmt_number(columns = p.value, decimals = 3)\n\n\n\n\n\n\n\nTable 3. Logistic Model for 30-day Readmission\n\n\nTerm\nOR\nstd.error\nstatistic\np-value\nLower 95% CI\nUpper 95% CI\n\n\n\n\nIntercept\n0.06\n0.310477797\n-9.074056\n0.000\n0.03\n0.11\n\n\ntreatmentStandardCare\n1.13\n0.105680489\n1.132052\n0.258\n0.92\n1.39\n\n\nAge (per year)\n1.01\n0.004433342\n3.257151\n0.001\n1.01\n1.02\n\n\nMale (vs Female)\n1.14\n0.105943160\n1.270461\n0.204\n0.93\n1.41\n\n\nComorbidity (per unit)\n1.37\n0.036799816\n8.649576\n0.000\n1.28\n1.48\n\n\n\n\n\n\n\nSurvival Analysis: Time to First Hospitalization\nWe estimate Kaplan–Meier curves by treatment and perform a log-rank test. See Figure 3 and Table 4.\n\nsurv_obj &lt;- with(patients, Surv(time = follow_up_m, event = event == 1))\nfit_km &lt;- survfit(surv_obj ~ treatment, data = patients)\n\n# Tidy the KM results for ggplot-based step curves with bands\nkm_df &lt;- broom::tidy(fit_km) %&gt;%\n  mutate(strata = str_replace(strata, \"treatment=\", \"\"))\nhead(km_df)\n\n\n  \n\n\n\n\nggplot(km_df, aes(x = time, y = estimate, color = strata, fill = strata)) +\n  geom_step(linewidth = 1) +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.15, color = NA) +\n  scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(x = \"Months since index\", y = \"Hospitalization-free survival\", color = \"Treatment\", fill = \"Treatment\")\n\n\n\n\nKaplan–Meier hospitalization-free survival by treatment with 95% confidence bands.\n\n\n\n\n\nlr &lt;- survdiff(surv_obj ~ treatment, data = patients)\n# Convert survdiff to a tidy one-row table\nchisq &lt;- unname(lr$chisq)\npval &lt;- pchisq(chisq, df = length(lr$n) - 1, lower.tail = FALSE)\nlr_tbl &lt;- tibble(\n  test = \"Log-rank\",\n  statistic = round(chisq, 3),\n  df = length(lr$n) - 1,\n  p_value = signif(pval, 3)\n)\ngt(lr_tbl) %&gt;%\n  tab_header(title = md(\"Table 4. Log-rank Test for Time to First Hospitalization\"))\n\n\n\n\n\n\n\nTable 4. Log-rank Test for Time to First Hospitalization\n\n\ntest\nstatistic\ndf\np_value\n\n\n\n\nLog-rank\n26.139\n1\n0.000000318\n\n\n\n\n\n\n\nEHR: Clinical Trajectories (e.g., HbA1c)\nWe summarize HbA1c change over time by treatment. See Figure 4.\n\na1c_summary &lt;- ehr %&gt;%\n  group_by(day, treatment) %&gt;%\n  summarise(\n    n = n(),\n    mean_a1c = mean(a1c),\n    se = sd(a1c) / sqrt(n),\n    .groups = \"drop\"\n  )\n\nggplot(a1c_summary, aes(day, mean_a1c, color = treatment, fill = treatment)) +\n  geom_line(linewidth = 1) +\n  geom_ribbon(aes(ymin = mean_a1c - 1.96 * se, ymax = mean_a1c + 1.96 * se), alpha = 0.2, color = NA) +\n  scale_x_continuous(breaks = c(0, 90, 180, 270), labels = c(\"0\", \"3\", \"6\", \"9\")) +\n  labs(x = \"Months since index (0, 3, 6, 9)\", y = \"HbA1c (%)\", color = \"Treatment\", fill = \"Treatment\")\n\n\n\n\nMean HbA1c trajectories with 95% CI by treatment.\n\n\n\n\nLinking EHR and Claims: Biomarkers vs Cost\nWe test whether improvement in HbA1c (negative change) is associated with lower PMPM. See Figure 5 and Table 5.\n\na1c_change &lt;- ehr %&gt;%\n  select(id, day, a1c) %&gt;%\n  arrange(id, day) %&gt;%\n  group_by(id) %&gt;%\n  summarise(\n    a1c_delta = a1c[day == 270] - a1c[day == 0],\n    .groups = \"drop\"\n  )\n\nclaims_ehr &lt;- claims_agg %&gt;%\n  left_join(a1c_change, by = \"id\") %&gt;%\n  left_join(patients %&gt;% select(id), by = \"id\")\n\nggplot(claims_ehr, aes(a1c_delta, pmpm, color = treatment)) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  scale_y_continuous(labels = dollar) +\n  labs(x = \"HbA1c change (9m - baseline; negative = improvement)\", y = \"PMPM ($)\", color = \"Treatment\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nAssociation between change in HbA1c (9m - baseline) and PMPM, by treatment with linear fits.\n\n\n\n\n\nfit_cost &lt;- lm(pmpm ~ a1c_delta + treatment + age + sex + comorbidity, data = claims_ehr)\ncost_tidy &lt;- broom::tidy(fit_cost, conf.int = TRUE) %&gt;%\n  mutate(across(c(estimate, conf.low, conf.high), ~round(.x, 2))) %&gt;%\n  mutate(term = recode(term,\n                       \"(Intercept)\" = \"Intercept\",\n                       \"a1c_delta\" = \"HbA1c change (9m - baseline)\",\n                       \"treatmentNewDrug\" = \"Treatment: NewDrug (vs StandardCare)\",\n                       \"age\" = \"Age (per year)\",\n                       \"sexMale\" = \"Male (vs Female)\",\n                       \"comorbidity\" = \"Comorbidity (per unit)\"))\n\ngt(cost_tidy) %&gt;%\n  cols_label(term = \"Term\", estimate = \"Estimate ($)\", conf.low = \"Lower 95% CI\", conf.high = \"Upper 95% CI\", p.value = \"p-value\") %&gt;%\n  tab_header(title = md(\"Table 5. PMPM vs HbA1c Change and Covariates\")) %&gt;%\n  fmt_number(columns = p.value, decimals = 3)\n\n\n\n\n\n\n\nTable 5. PMPM vs HbA1c Change and Covariates\n\n\nTerm\nEstimate ($)\nstd.error\nstatistic\np-value\nLower 95% CI\nUpper 95% CI\n\n\n\n\nIntercept\n1708.76\n214.488313\n7.9666733\n0.000\n1288.11\n2129.40\n\n\nHbA1c change (9m - baseline)\n-64.62\n82.690750\n-0.7814828\n0.435\n-226.79\n97.55\n\n\ntreatmentStandardCare\n572.34\n82.361203\n6.9491632\n0.000\n410.82\n733.86\n\n\nAge (per year)\n36.06\n2.987932\n12.0697236\n0.000\n30.20\n41.92\n\n\nMale (vs Female)\n136.41\n71.877599\n1.8978550\n0.058\n-4.55\n277.38\n\n\nComorbidity (per unit)\n1008.25\n25.409613\n39.6798774\n0.000\n958.42\n1058.08\n\n\n\n\n\n\n\nBest Practices and Next Steps\n\nAddress confounding: Propensity scores (matching/weighting), doubly robust estimators, or instrumental variables when appropriate.\nModel skewed costs: Use Gamma GLM with log link or two-part models for zero-inflated costs.\nTime-to-event: Consider Cox models and assess proportional hazards (e.g., Schoenfeld residuals).\nMissing data: Multiple imputation and sensitivity analyses.\nGovernance: Claims/EHR use requires privacy, security, IRB/contract compliance, and a data dictionary for reproducibility.\nReproducibility: Version control, code review, and pre-specified analysis plans.\n\nAppendix: Alternative Cost Model (Gamma GLM)\n\nfit_gamma &lt;- glm(pmpm ~ a1c_delta + treatment + age + sex + comorbidity,\n                 data = claims_ehr,\n                 family = Gamma(link = \"log\"))\n\npred_df &lt;- claims_ehr %&gt;%\n  mutate(a1c_delta_q = cut(a1c_delta, breaks = quantile(a1c_delta, probs = seq(0,1,0.2), na.rm = TRUE),\n                           include.lowest = TRUE, labels = paste0(\"Q\", 1:5))) %&gt;%\n  group_by(treatment, a1c_delta_q) %&gt;%\n  summarise(age = mean(age), comorbidity = mean(comorbidity),\n            sex = names(sort(table(sex), decreasing = TRUE))[1],\n            a1c_delta = mean(a1c_delta, na.rm = TRUE),\n            .groups = \"drop\") %&gt;%\n  mutate(pred = predict(fit_gamma, newdata = ., type = \"response\"))\n\nggplot(pred_df, aes(a1c_delta_q, pred, fill = treatment)) +\n  geom_col(position = position_dodge(width = 0.7)) +\n  scale_y_continuous(labels = dollar) +\n  labs(x = \"HbA1c change quantile (9m - baseline; Q1 = greatest improvement)\",\n       y = \"Predicted PMPM ($)\", fill = \"Treatment\")\n\n\n\n\nPredicted PMPM from Gamma GLM by HbA1c change quantiles and treatment.\n\n\n\n\nSession Info\n\nsessionInfo()\n\nR version 4.4.3 (2025-02-28)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.3.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] scales_1.4.0    glue_1.8.0      gt_1.0.0        broom_1.0.8    \n [5] survival_3.8-3  lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1  \n [9] dplyr_1.1.4     purrr_1.0.4     readr_2.1.5     tidyr_1.3.1    \n[13] tibble_3.3.0    ggplot2_3.5.2   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] sass_0.4.10        generics_0.1.4     xml2_1.3.8         stringi_1.8.7     \n [5] lattice_0.22-6     hms_1.1.3          digest_0.6.37      magrittr_2.0.3    \n [9] evaluate_1.0.4     grid_4.4.3         timechange_0.3.0   RColorBrewer_1.1-3\n[13] fastmap_1.2.0      jsonlite_2.0.0     Matrix_1.7-2       backports_1.5.0   \n[17] mgcv_1.9-1         cli_3.6.5          rlang_1.1.6        litedown_0.7      \n[21] commonmark_1.9.5   splines_4.4.3      base64enc_0.1-3    withr_3.0.2       \n[25] yaml_2.3.10        tools_4.4.3        tzdb_0.5.0         vctrs_0.6.5       \n[29] R6_2.6.1           lifecycle_1.0.4    htmlwidgets_1.6.4  pkgconfig_2.0.3   \n[33] pillar_1.10.2      gtable_0.3.6       xfun_0.52          tidyselect_1.2.1  \n[37] rstudioapi_0.17.1  knitr_1.50         farver_2.1.2       nlme_3.1-167      \n[41] htmltools_0.5.8.1  labeling_0.4.3     rmarkdown_2.29     compiler_4.4.3    \n[45] markdown_2.0"
  }
]